{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtiPhadke/Arti_INFO5731_Spring2023/blob/main/INFO5731_Assignment_Four_ArtiPhadke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS1_OHwcUdmD"
      },
      "source": [
        "Arti Phadke - Assignment#4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "\n",
        "# importing the libraries required for the topic modelling\n",
        "import pandas as pd\n",
        "# importing the library for regular expression processing\n",
        "import re\n",
        "# importing the libraries required for preprocessing the data\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "# import the functions from gensim library\n",
        "import gensim.corpora as corpora\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "ywbqjiBLoJvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "b132da2e-6192-48c1-fb8d-1949de85932b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3)\n"
          ]
        }
      ],
      "source": [
        "# Location of the dataset CSV: https://github.dev/ArtiPhadke/Arti_INFO5731_Spring2023/blob/main/movies_sentiment_data.csv\n",
        "# However, facing issues while accessing data from the github location, hence downloaded and used the file from colab\n",
        "df_movies=pd.read_csv('movies_sentiment_data.csv')\n",
        "print(df_movies.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNnL9kZpUG0",
        "outputId": "62a46983-12e9-44b3-9893-bd81529061a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    detective batman at its peak great storyline j...\n",
              "1    i just got out of the batmanthis movie really ...\n",
              "2    i have been absolutely fizzing to see the batm...\n",
              "3    the riddlerpaul dano spoton how did it take th...\n",
              "4    star rating  brilliant  very good  okay  poor ...\n",
              "Name: clean_text_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# create a new column to store the cleaned data: clean_text_processed\n",
        "df_movies['clean_text_processed'] = \\\n",
        "\n",
        "# removing the special characters\n",
        "df_movies['clean_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "\n",
        "# converting the data to lowercase\n",
        "df_movies['clean_text_processed'] = \\\n",
        "df_movies['clean_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "# printing out the first rows of data\n",
        "df_movies['clean_text_processed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKtL_mV2qVSe",
        "outputId": "068316dd-7344-4c1e-937b-bae393c9ba19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['detective', 'batman', 'peak', 'great', 'storyline', 'dark', 'universe', 'weve', 'come', 'expect', 'dc', 'gloomy', 'gritty', 'dark', 'tone', 'film', 'exactly', 'wanted', 'think', 'movie', 'theres', 'beautiful', 'cinematography', 'great', 'score']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing the stopwords from English\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# adding few more commonly used words to stopwords list\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # removing the punctuation marks\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    # if the word is not in the stopwords, then add the word to the list processing list\n",
        "    return [[word for word in simple_preprocess(str(doc)) \n",
        "             if word not in stop_words] for doc in texts]\n",
        "\n",
        "# convert to list\n",
        "data = df_movies.clean_text_processed.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "# remove stop words\n",
        "data_words = remove_stopwords(data_words)\n",
        "\n",
        "# print the first 30 words from the list\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "The features that are being used for the topic modelling in this case, are represented in form of the list and converted to the dictionary in subsequent code. Some examples of the features are 'detective', 'batman', 'peak', 'great', 'storyline', 'dark', 'universe', etc."
      ],
      "metadata": {
        "id": "286GF9aS25Dj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wa_Tl15qfG5",
        "outputId": "0c744509-ff48-4c7f-d82e-597a069d769c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]\n"
          ]
        }
      ],
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "# Create Corpus\n",
        "texts = data_words\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "# print the first 30 corpus entries\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcDo3JC3qjcS",
        "outputId": "821df5af-b5df-4119-99ec-8afa8c914fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.030*\"batman\" + 0.014*\"like\" + 0.012*\"one\" + 0.010*\"film\" + 0.009*\"movie\" '\n",
            "  '+ 0.008*\"even\" + 0.007*\"riddler\" + 0.007*\"penguin\" + 0.006*\"pattinson\" + '\n",
            "  '0.006*\"farrell\"'),\n",
            " (1,\n",
            "  '0.020*\"batman\" + 0.016*\"movie\" + 0.011*\"film\" + 0.010*\"one\" + 0.007*\"good\" '\n",
            "  '+ 0.006*\"great\" + 0.006*\"even\" + 0.006*\"dark\" + 0.005*\"wayne\" + '\n",
            "  '0.005*\"penguin\"'),\n",
            " (2,\n",
            "  '0.031*\"batman\" + 0.013*\"movie\" + 0.011*\"film\" + 0.008*\"dark\" + 0.008*\"good\" '\n",
            "  '+ 0.007*\"like\" + 0.007*\"great\" + 0.006*\"even\" + 0.006*\"one\" + '\n",
            "  '0.005*\"reeves\"'),\n",
            " (3,\n",
            "  '0.019*\"batman\" + 0.017*\"film\" + 0.012*\"movie\" + 0.009*\"good\" + 0.008*\"even\" '\n",
            "  '+ 0.007*\"pattinson\" + 0.007*\"like\" + 0.006*\"actor\" + 0.006*\"long\" + '\n",
            "  '0.006*\"role\"'),\n",
            " (4,\n",
            "  '0.032*\"batman\" + 0.014*\"movie\" + 0.011*\"great\" + 0.010*\"film\" + '\n",
            "  '0.009*\"dark\" + 0.008*\"one\" + 0.008*\"riddler\" + 0.007*\"robert\" + '\n",
            "  '0.006*\"like\" + 0.006*\"absolutely\"'),\n",
            " (5,\n",
            "  '0.025*\"batman\" + 0.011*\"film\" + 0.009*\"one\" + 0.006*\"riddler\" + '\n",
            "  '0.006*\"good\" + 0.006*\"reeves\" + 0.006*\"even\" + 0.006*\"movie\" + 0.006*\"like\" '\n",
            "  '+ 0.005*\"pattinson\"'),\n",
            " (6,\n",
            "  '0.029*\"movie\" + 0.027*\"batman\" + 0.011*\"great\" + 0.009*\"film\" + 0.009*\"one\" '\n",
            "  '+ 0.008*\"long\" + 0.008*\"really\" + 0.007*\"still\" + 0.007*\"think\" + '\n",
            "  '0.007*\"like\"'),\n",
            " (7,\n",
            "  '0.017*\"batman\" + 0.014*\"film\" + 0.008*\"movie\" + 0.007*\"riddler\" + '\n",
            "  '0.006*\"bit\" + 0.006*\"even\" + 0.006*\"pattinson\" + 0.006*\"one\" + 0.006*\"like\" '\n",
            "  '+ 0.005*\"reeves\"'),\n",
            " (8,\n",
            "  '0.017*\"batman\" + 0.011*\"film\" + 0.008*\"get\" + 0.008*\"one\" + 0.008*\"movie\" + '\n",
            "  '0.006*\"going\" + 0.006*\"really\" + 0.006*\"something\" + 0.005*\"time\" + '\n",
            "  '0.005*\"think\"'),\n",
            " (9,\n",
            "  '0.020*\"batman\" + 0.009*\"movie\" + 0.008*\"like\" + 0.006*\"pattinson\" + '\n",
            "  '0.006*\"good\" + 0.006*\"get\" + 0.005*\"film\" + 0.005*\"great\" + 0.005*\"riddler\" '\n",
            "  '+ 0.005*\"city\"')]\n"
          ]
        }
      ],
      "source": [
        "# set the number of topics = 10\n",
        "num_topics = 10\n",
        "\n",
        "# creating the LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "\n",
        "# printing the top 10 keywords in every one of the ten topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(2) The top 10 clusters for topic modeling are as shown above.\n",
        "\n",
        "topic 1 words list: batman, like, one, film, movie, even, riddler, penguin, pattinson, farrell\n",
        "topic 2 words list: batman, movie, film, one, good, great, even, dark, wayne, penguin\n",
        "topic 3 words list: batman, movie, film, dark, good, like, great, even, one, reeves\n",
        "topic 4 words list: batman, film, movie, good, even, pattinson, like, actor, long, role\n",
        "topic 5 words list: batman, movie, great, film, dark, one, riddler, robert, like, absolutely\n",
        "topic 6 words list: batman, film, one, riddler, good, reeves, even, movie, like, pattinson\n",
        "topic 7 words list: movie, batman, great, film, one, long, really, still, think, like\n",
        "topic 8 words list: batman, film, movie, riddler, bit, even, pattinson, one, like, reeves\n",
        "topic 9 words list: batman, film, get, one, movie, going, really, something, time, think\n",
        "topic 10 words list: batman, movie, like, pattinson, good, get, film, great, riddler, city"
      ],
      "metadata": {
        "id": "ZrN_2qXe1pmE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idgE9dO5qnFd",
        "outputId": "799bee7d-2da5-4141-a6d6-c33e09e9fedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (3.4.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (52.0.0.post20210125)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.24.2)\n",
            "Requirement already satisfied: numexpr in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.10.1)\n",
            "Requirement already satisfied: funcy in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: pandas>=1.3.4 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2021.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\arti phadke\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFj2H6wWrR5H",
        "outputId": "e0b4368b-d0a1-47fc-f770-42a5b7be2a1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0z8ffl_Hqq45",
        "outputId": "830ffb7b-0fa8-4902-eb91-28ef9c283dc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Arti Phadke\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1301616791366013602396759735\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1301616791366013602396759735_data = {\"mdsDat\": {\"x\": [0.009159606295623526, -0.012659804908858603, -0.05074227319132911, 0.048049207119051605, 0.020760943083280768, -0.008604380672399416, 0.0005401591568128027, 0.04022727055961524, -0.022199177622606037, -0.024531549819190725], \"y\": [0.05163124865804848, -0.0010858189829995014, 0.0012813505774082934, -0.03227997142741374, -0.0004689761767941749, -0.042826938960420585, -0.010163963630638578, 0.024905250794550717, -0.00205358766153158, 0.01106140680979067], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [21.324265217928044, 15.826341600621324, 15.476086476136045, 12.055741959576107, 9.172102984015176, 8.675053177565212, 8.144506050860764, 6.010234211693121, 3.2233922385775324, 0.09227608302667391]}, \"tinfo\": {\"Term\": [\"batman\", \"movie\", \"film\", \"one\", \"like\", \"great\", \"riddler\", \"even\", \"good\", \"dark\", \"penguin\", \"still\", \"pattinson\", \"reeves\", \"farrell\", \"city\", \"bruce\", \"long\", \"really\", \"wayne\", \"story\", \"feel\", \"see\", \"im\", \"car\", \"robert\", \"crime\", \"end\", \"dano\", \"get\", \"fit\", \"overall\", \"firstly\", \"disappointment\", \"drivel\", \"hoping\", \"hype\", \"alone\", \"awesomeat\", \"negative\", \"headline\", \"connect\", \"wellmade\", \"ways\", \"invested\", \"amazingthis\", \"true\", \"reigns\", \"iteration\", \"huge\", \"surface\", \"relationships\", \"nearly\", \"franchise\", \"undeveloped\", \"viewing\", \"fires\", \"grounded\", \"cylinders\", \"organic\", \"boring\", \"finish\", \"underwhelming\", \"enjoy\", \"super\", \"trilogy\", \"good\", \"recommend\", \"still\", \"batman\", \"actor\", \"amazing\", \"movie\", \"film\", \"even\", \"great\", \"think\", \"villain\", \"action\", \"theme\", \"end\", \"really\", \"feels\", \"one\", \"pattinson\", \"fan\", \"role\", \"nolan\", \"like\", \"feel\", \"people\", \"robert\", \"time\", \"kravitz\", \"dano\", \"batmans\", \"long\", \"riddler\", \"get\", \"also\", \"say\", \"penguin\", \"de\", \"niro\", \"employing\", \"mode\", \"inner\", \"bob\", \"getting\", \"standing\", \"pulls\", \"imax\", \"affectively\", \"ace\", \"aided\", \"stops\", \"chinlunds\", \"precatwoman\", \"arresting\", \"field\", \"bombast\", \"darker\", \"siege\", \"tall\", \"quakes\", \"kane\", \"asskicking\", \"ton\", \"visuals\", \"unlikely\", \"dread\", \"cursader\", \"caped\", \"design\", \"giacchino\", \"fraser\", \"fing\", \"movie\", \"jeffrey\", \"batman\", \"farrell\", \"one\", \"even\", \"great\", \"really\", \"means\", \"see\", \"penguin\", \"wright\", \"pattinson\", \"book\", \"kravitz\", \"still\", \"dark\", \"im\", \"zoe\", \"comic\", \"bruce\", \"film\", \"love\", \"colin\", \"get\", \"kyle\", \"characters\", \"dano\", \"like\", \"matt\", \"part\", \"story\", \"robert\", \"absolutely\", \"reeves\", \"think\", \"riddler\", \"good\", \"character\", \"long\", \"time\", \"onto\", \"editor\", \"heavily\", \"seemed\", \"mysterythe\", \"wondered\", \"books\", \"catch\", \"burner\", \"borrow\", \"sports\", \"becoming\", \"portion\", \"fear\", \"pace\", \"buick\", \"interested\", \"tired\", \"origin\", \"emokid\", \"stop\", \"screen\", \"stories\", \"budget\", \"device\", \"presented\", \"focused\", \"versus\", \"donning\", \"hand\", \"general\", \"car\", \"connection\", \"attempt\", \"year\", \"plot\", \"grayson\", \"level\", \"weve\", \"youve\", \"falcone\", \"audience\", \"bruce\", \"crime\", \"wayne\", \"greatest\", \"barely\", \"long\", \"better\", \"batman\", \"theres\", \"everyone\", \"film\", \"part\", \"role\", \"would\", \"took\", \"old\", \"like\", \"think\", \"see\", \"hes\", \"one\", \"great\", \"robert\", \"reeves\", \"really\", \"get\", \"also\", \"even\", \"movie\", \"penguin\", \"good\", \"pattinson\", \"view\", \"except\", \"direction\", \"harley\", \"credits\", \"editing\", \"misery\", \"mistaken\", \"sorely\", \"member\", \"wrong\", \"pitiful\", \"escape\", \"quinn\", \"peak\", \"script\", \"boo\", \"sleepy\", \"obvious\", \"tried\", \"dc\", \"biggest\", \"fest\", \"ill\", \"rhetoric\", \"antihero\", \"terrible\", \"destroying\", \"worse\", \"explosive\", \"white\", \"privileged\", \"absolute\", \"book\", \"final\", \"yet\", \"emo\", \"thought\", \"movie\", \"could\", \"film\", \"one\", \"like\", \"comic\", \"batman\", \"really\", \"pattinson\", \"cast\", \"dark\", \"riddler\", \"end\", \"good\", \"hes\", \"feel\", \"great\", \"penguin\", \"character\", \"long\", \"even\", \"bit\", \"much\", \"also\", \"detective\", \"farrell\", \"robert\", \"time\", \"think\", \"thrillingit\", \"creepy\", \"worthy\", \"surpassedrobert\", \"actingthe\", \"majestic\", \"special\", \"scary\", \"rewarding\", \"oscar\", \"toobeautifully\", \"populationpaul\", \"evokes\", \"sense\", \"shot\", \"gives\", \"extremely\", \"gave\", \"dramatic\", \"performances\", \"itthis\", \"high\", \"complex\", \"spends\", \"momentits\", \"decent\", \"irritating\", \"shots\", \"overly\", \"generic\", \"rest\", \"watch\", \"work\", \"feel\", \"riddler\", \"batman\", \"one\", \"long\", \"score\", \"paul\", \"reeves\", \"movie\", \"end\", \"also\", \"film\", \"penguin\", \"trying\", \"cast\", \"like\", \"good\", \"dano\", \"see\", \"even\", \"dark\", \"farrell\", \"get\", \"say\", \"characters\", \"time\", \"bruce\", \"robert\", \"would\", \"wayne\", \"movieit\", \"mood\", \"filmjust\", \"expect\", \"knightthe\", \"adventure\", \"itgo\", \"actionpacked\", \"theatre\", \"avengers\", \"moisty\", \"immediately\", \"hasif\", \"youll\", \"american\", \"crimes\", \"ensemble\", \"corrupt\", \"darkness\", \"rob\", \"employees\", \"nowto\", \"taxi\", \"peak\", \"telling\", \"strains\", \"housed\", \"badboys\", \"written\", \"boys\", \"parents\", \"city\", \"james\", \"dark\", \"movies\", \"noir\", \"hero\", \"detective\", \"batman\", \"riddler\", \"like\", \"film\", \"movie\", \"pattinson\", \"great\", \"hours\", \"together\", \"reeves\", \"farrell\", \"dano\", \"think\", \"even\", \"kravitz\", \"im\", \"one\", \"penguin\", \"really\", \"cinematography\", \"robert\", \"much\", \"paul\", \"also\", \"seen\", \"wayne\", \"get\", \"time\", \"long\", \"bore\", \"batcharisma\", \"caliber\", \"please\", \"reviews\", \"understand\", \"close\", \"hated\", \"complete\", \"certainly\", \"sequel\", \"pattison\", \"pining\", \"specialbut\", \"southamptonwith\", \"wings\", \"stuck\", \"exception\", \"realise\", \"lowerim\", \"threat\", \"racked\", \"topless\", \"built\", \"minutes\", \"ripoff\", \"angry\", \"dead\", \"suddenly\", \"wraps\", \"make\", \"knight\", \"mess\", \"keeps\", \"something\", \"found\", \"going\", \"opening\", \"mr\", \"film\", \"absolutely\", \"batman\", \"always\", \"favourite\", \"terrible\", \"scenes\", \"riddler\", \"robert\", \"time\", \"one\", \"dark\", \"bruce\", \"get\", \"good\", \"even\", \"movie\", \"like\", \"think\", \"im\", \"wayne\", \"great\", \"see\", \"character\", \"made\", \"end\", \"really\", \"little\", \"would\", \"reeves\", \"effort\", \"saga\", \"shoehorned\", \"drawn\", \"faces\", \"overacting\", \"overly\", \"shots\", \"momentits\", \"spends\", \"complex\", \"itthis\", \"dramatic\", \"rich\", \"blatantly\", \"biden\", \"generic\", \"free\", \"dexter\", \"mascarade\", \"ironic\", \"woke\", \"diversity\", \"orphan\", \"commentary\", \"missteps\", \"men\", \"boo\", \"joe\", \"throat\", \"sleepy\", \"hard\", \"trying\", \"oscar\", \"making\", \"like\", \"feels\", \"crime\", \"story\", \"white\", \"every\", \"characters\", \"batman\", \"movie\", \"long\", \"universe\", \"good\", \"feel\", \"reeves\", \"one\", \"film\", \"hes\", \"riddler\", \"lot\", \"get\", \"think\", \"time\", \"bit\", \"become\", \"penguin\", \"even\", \"pattinson\", \"farrell\", \"everything\", \"recognise\", \"moviethis\", \"fantasticpaul\", \"wise\", \"composition\", \"deserves\", \"deservesrobert\", \"grandeur\", \"totally\", \"loud\", \"bombastic\", \"madness\", \"needsproduction\", \"musicthe\", \"reevestotally\", \"homicidal\", \"visceral\", \"damn\", \"ita\", \"grey\", \"revs\", \"give\", \"againdirection\", \"fori\", \"waiting\", \"worth\", \"design\", \"mature\", \"goosebumpsfight\", \"greatcolin\", \"greig\", \"giacchino\", \"done\", \"couldnt\", \"felt\", \"fraser\", \"fing\", \"christian\", \"great\", \"batman\", \"city\", \"riddler\", \"made\", \"reeves\", \"bruce\", \"andy\", \"film\", \"theme\", \"cat\", \"still\", \"kyle\", \"robert\", \"movie\", \"dark\", \"pattinson\", \"one\", \"like\", \"even\", \"wayne\", \"people\", \"see\", \"dano\", \"penguin\", \"get\", \"end\", \"character\", \"good\", \"farrell\", \"really\", \"time\", \"presence\", \"darkness\", \"shadows\", \"shadow\", \"humor\", \"deaths\", \"somewhere\", \"childhood\", \"rob\", \"everywhere\", \"kylecat\", \"hiding\", \"casts\", \"corrupt\", \"frailty\", \"vengeance\", \"godfatherbatman\", \"achievement\", \"bringing\", \"ridding\", \"compositions\", \"realizes\", \"lt\", \"condemnation\", \"cinematographer\", \"terrorizing\", \"power\", \"scowls\", \"number\", \"godfather\", \"batman\", \"parents\", \"city\", \"american\", \"side\", \"selena\", \"scene\", \"quite\", \"movie\", \"penguin\", \"heath\", \"wayne\", \"films\", \"great\", \"noir\", \"twilight\", \"riddler\", \"im\", \"farrell\", \"scenes\", \"one\", \"car\", \"film\", \"reeves\", \"bruce\", \"still\", \"cat\", \"see\", \"even\", \"pattinson\", \"zoe\", \"really\", \"like\", \"good\", \"dark\", \"feel\", \"would\", \"long\", \"story\", \"also\", \"robert\", \"dano\", \"get\"], \"Freq\": [333.0, 178.0, 159.0, 114.0, 98.0, 83.0, 68.0, 88.0, 90.0, 58.0, 54.0, 43.0, 65.0, 50.0, 49.0, 26.0, 48.0, 61.0, 67.0, 39.0, 39.0, 46.0, 47.0, 41.0, 28.0, 55.0, 28.0, 47.0, 45.0, 52.0, 5.102979209476142, 5.08357182278923, 5.057583774474679, 5.05260800894627, 5.030427397748457, 4.294481776567786, 4.10692946358714, 4.068433042422534, 4.04591022852426, 4.008030463539068, 3.9145807822513565, 3.9160204532083434, 3.900010897375497, 3.8616693315743307, 3.837218084478211, 3.834873477491118, 3.8099963781455366, 3.7941281969636886, 3.797139580727739, 3.7875983472521786, 3.766161940513043, 3.7744591461916777, 3.7616898005751085, 3.762457164206444, 3.7377096870958852, 3.721900267993914, 3.7166797756857815, 3.696779133187196, 3.6863920714207, 3.6770730968707923, 7.99041646410122, 5.9417090411626345, 5.342765826578053, 7.5885419085037205, 7.470087925250458, 8.054807951230455, 38.468284498124504, 7.933493982983648, 20.025885921679084, 92.74264488153437, 12.316747633621642, 13.877779568519243, 48.835773652791424, 41.79771905648711, 27.098164935940943, 24.293723242934163, 18.68914262380477, 8.591192364259378, 11.077026751491564, 8.477202225121008, 14.181695663005996, 16.614184451488654, 9.004701120353939, 22.02620242617965, 15.742513289141693, 9.275652379348275, 10.696245017295567, 11.007304506739604, 17.136797798268752, 12.055571619444496, 10.30048102668669, 12.724584120711604, 11.971677343663373, 10.72502668401933, 11.099607290491836, 9.202780487114905, 11.528528994478846, 11.502045962056155, 10.381202150154454, 10.08235549486462, 9.265722970486232, 9.290788108487419, 2.1766126889122908, 1.9701488421667022, 2.047906687238263, 2.0116663403527073, 1.9806293895842624, 2.0426617316787143, 1.8917414384022202, 1.956502465740455, 1.9855367388089433, 1.954600992979028, 1.993894547915059, 1.8872054304919166, 1.833719197693392, 1.8529540364287225, 1.9051624446421596, 1.8693574457431315, 1.8299771803654705, 1.846383668157097, 1.8076562964893435, 1.8744064049198237, 1.8436333053029068, 1.8296609951012424, 1.8399688912548466, 1.783053363105759, 1.7650237482011333, 1.784381212945633, 1.7331958853275238, 1.7782240019705913, 1.752471770425756, 1.6991950023479148, 1.8187381731234151, 2.738064850785337, 3.7730840373030317, 3.443893489529254, 2.699048487068777, 36.184084635926034, 6.341536337686152, 58.378226578843986, 12.760362976716436, 24.276518339562095, 18.584457062832875, 16.607443601280497, 14.192523938632803, 3.228750774157727, 10.709662058323632, 11.70062490083996, 6.954401634491412, 12.767667176994816, 5.8500656591630324, 9.007594580191894, 9.528646346299285, 11.461436456461241, 9.053470047689116, 6.893762303337941, 5.476877258455023, 9.509998983632986, 20.59777705853099, 4.849659587781604, 6.455680115961686, 9.556664593616068, 4.383728982415072, 7.293576453501291, 8.613610039719676, 13.09727254957367, 6.319917218345762, 5.220766424810955, 7.447132436355618, 8.565874658903464, 6.2557827893912, 8.006834997009973, 8.657218721825645, 9.041288513338927, 9.971228754288187, 7.2576947492115895, 8.0614153719196, 7.267074869293729, 5.052540782548966, 2.575421831583295, 2.690267321440363, 4.701302026290014, 2.6056610178552524, 2.45239948674299, 2.5509193632053915, 2.5217754415094986, 2.3980358815013125, 2.421361053347959, 2.3005550764713565, 2.401468178782511, 2.3942629132869273, 2.431105546520804, 2.3754956576295876, 2.444757971797618, 2.86217017536132, 2.369756681975299, 2.2530159278323483, 2.395971034335581, 7.443799871274786, 2.220574672744841, 2.2626342372943, 2.291845891797233, 2.352972743252995, 2.218219828820078, 4.66797949212424, 2.3744274861763395, 2.256846594363842, 5.9076433886552016, 2.356532478556328, 12.189126716967417, 3.8196995865849344, 3.835552575503809, 6.882091702490704, 6.726447732606366, 2.797525482597691, 5.336051247288222, 6.934902219553175, 2.718859847914499, 6.637718758832744, 3.950840335504624, 12.507900386225273, 8.40420742507311, 10.1083267191419, 4.682916332112334, 3.936930525561057, 13.013484147646881, 7.7352325658152585, 39.39784786049729, 7.247284922173419, 5.9742342707411185, 20.878050752469594, 5.839650186601306, 7.766846728070131, 8.30572693398369, 5.439383414259703, 5.4837865339327525, 13.100296533843514, 10.027319285370856, 8.537650085983172, 6.963840183343216, 12.311306666377941, 10.47932689814819, 8.790910577373795, 8.348465833501537, 9.31137047011941, 8.175858056662866, 7.619234363927267, 9.269151357180034, 11.100985625305771, 7.204175749977086, 7.536361016753391, 7.3003738963315, 2.881380811531899, 2.864848118476353, 2.8659483307894784, 2.799539671904902, 2.776523347566074, 2.765832723267346, 2.693222032734162, 2.7670325995733123, 2.701884592488376, 2.724229455102888, 2.58446360283679, 2.6688305407137243, 2.594930667120205, 2.5332136418437132, 1.460539857877361, 3.231768729484092, 2.871367511545301, 2.864274952807721, 1.6269770648550292, 1.6116990633015118, 5.261809747770187, 3.052210757848926, 1.5864283785285427, 1.5759596531785807, 1.5715026207928597, 1.5409139826136595, 4.348074236998604, 1.5091687535685208, 5.782159753623316, 2.0396228318095706, 3.9209202262705456, 3.841306283754151, 2.859782842604912, 6.459973396416357, 3.548774877002821, 7.096836081649064, 4.150909155381149, 4.659691884637738, 30.859223965567335, 5.1079160359699145, 23.146258045070773, 17.641957204256677, 15.335482272839394, 5.422982448600529, 29.42750810693711, 10.811556196802147, 10.519429699449182, 6.117475153724878, 9.282096929098996, 9.945521436360945, 7.971502916387847, 10.776673017629475, 6.181548939302664, 7.177110542392521, 8.964839471982632, 7.374471825282157, 6.58285128280537, 7.490823869755626, 8.549557201578263, 4.797216860421667, 6.199422797030499, 6.4951645568688665, 5.573535657864289, 6.300109225186137, 6.238976504495124, 5.3156505817379385, 5.354107594442127, 2.1849404150936196, 2.1408888295520017, 2.136136525633718, 2.0285645790158955, 2.0136354996345087, 2.0164444496385174, 1.9791396667344858, 1.957842761773694, 1.878198852235903, 2.9020457406525946, 1.8283661196051049, 1.831411465655606, 1.6389803261548053, 1.672765484147764, 2.6814477891971293, 4.216071749673438, 2.402426859340918, 2.3310450659664035, 0.9487515956376285, 1.997921852996934, 0.8976666330058373, 1.9658936082627152, 0.8441577931753291, 0.8290369207750903, 0.8284069030096752, 0.9954058421804202, 2.3544524375183618, 0.7598611931476503, 0.7544353091736229, 1.4633214118142353, 2.3380581486790004, 2.9599119245916343, 2.2055201033699605, 7.429534639894493, 9.151152036095251, 33.07125620552155, 13.725391152727747, 7.959231275541691, 3.414930305768203, 4.351258471440501, 5.96525649313738, 13.565121174983533, 5.735019232701874, 5.472864045687179, 11.193211855830667, 5.930021290715844, 3.9200863556078684, 3.786964159313503, 6.619066108202697, 6.118064087003904, 4.594248926892356, 4.658923614323884, 5.6636526043567565, 4.711019950607413, 4.450361641200316, 4.426347371118936, 3.638549368962485, 3.839200846457339, 4.194982546144691, 4.123813063181742, 4.262874301283134, 3.6897884350547723, 3.5741185114153886, 1.605188318161671, 1.6025855872890915, 1.5905872074899197, 2.7953467378857404, 1.5681544207029023, 1.5652545603077248, 1.5437432547140737, 1.5402837277311354, 1.5382904428362831, 1.5327922107806418, 1.5340501950253929, 1.486864676887318, 1.4851280230283108, 1.469678131571704, 1.931984388503083, 1.0947675387424578, 1.0965304181840319, 1.7994023268771726, 1.7299984670642248, 1.7524801895227349, 1.0790089166342354, 1.0965822365603108, 1.038002581670202, 1.2077957919442965, 1.0456323278306878, 1.0467844957168233, 1.0254659797944838, 1.03828086814688, 0.9972724941965346, 0.9910638511857754, 1.7642409219517265, 7.292429764491997, 2.520223643006179, 13.274818979344326, 5.334646855589319, 3.856792951384698, 3.087787998162861, 5.4772380900921736, 27.16414399734442, 9.174470378545715, 11.61914184459908, 14.011394206820075, 15.046384783847929, 7.729002326726534, 8.73613163230558, 4.646208298211347, 3.7713917674452557, 5.7869716417336505, 5.703709565365319, 5.337062702819905, 6.029187466210833, 7.080600179616846, 4.877761489853464, 4.885969183168648, 7.3906104709177995, 5.320867807950746, 5.803039416352726, 3.8050682278564416, 5.250049454116118, 4.479586555371189, 3.7844618103261674, 4.1999529415295624, 3.711009086176184, 3.863189743615162, 3.98188883961045, 3.9318414284085286, 3.862299058146097, 2.4196693691560043, 2.381802671756312, 2.33186012763718, 2.142593442633252, 2.1451568701586847, 2.134630671288735, 1.968938753407254, 3.0926231566706135, 2.3832752200706078, 2.25462514017805, 2.5538896264267907, 2.1165418529427122, 1.1505962336582158, 1.102258917704184, 1.085703574788025, 1.07323589344452, 1.1459236585741326, 1.1472409516600248, 1.0868127387348205, 1.1358570204610468, 1.1096460829297903, 1.0374609830060844, 1.1111747396387046, 1.1066984779259101, 1.108515993852296, 1.0406833211139677, 1.030514235673296, 1.0841354441732498, 1.0587768921710636, 1.038160357642536, 4.732094869094828, 3.574066451475559, 1.7931259372945973, 1.811858880010841, 4.686037402238839, 2.980170316116796, 6.11751067512065, 2.947331987032945, 1.7638256055457657, 17.294178784575195, 4.411956475810951, 24.932711730388913, 2.5215041250924495, 2.6634932166920007, 2.1498872698941636, 3.8304210857965373, 6.715991592428388, 5.616193126843043, 5.088962213555286, 8.314059006177146, 5.340027872569888, 4.816409019698047, 4.880134954009551, 6.507772151821063, 6.038147793298079, 6.695730257042734, 5.082769431026419, 4.307328710000268, 3.810356459841428, 3.7543692593552227, 4.374786578662545, 3.7973274305122335, 3.4973767055923695, 3.3114717715544826, 3.5324921113594705, 3.540808827659217, 3.08383116926351, 3.141390460957052, 3.105522014524293, 2.2391968145607946, 2.2331499072702647, 2.22495850485698, 2.2141970596789187, 2.204852158162717, 2.2044018648473718, 2.1927312597344772, 2.1896855934375683, 2.1518155554061997, 2.151847705296737, 2.1435694007550907, 2.1139839023956544, 2.086104296712914, 2.7096685702939127, 1.4231845627338082, 1.397766274731482, 2.5253094070832223, 1.3876067144738449, 1.36624067661398, 1.3518313879468533, 1.339438579383796, 1.3324449065288952, 1.3435239536559018, 1.3292412186487996, 1.3144309331651518, 1.2929810133181576, 1.299358967057312, 2.2764817245843827, 1.2798365792839004, 1.218183903287273, 2.0946670790738606, 3.5087007112977093, 6.307779296263037, 2.1992567132744605, 2.6551947700064633, 13.498405498160851, 4.663643246876254, 5.204589511145549, 6.4818169806764745, 2.543040753681969, 3.951869610899546, 4.96732760563167, 18.16750175616789, 11.95255926321191, 6.116553306129203, 3.025290085981952, 5.924702633879836, 4.49303371503321, 4.53232867518276, 5.964266484022971, 6.376205174804607, 3.820731961027918, 4.266776035082905, 3.3377583793756473, 3.9068500217561257, 3.966248211034796, 3.701115662837963, 3.0388583140278382, 2.9433916496748216, 3.49732471609083, 3.700364329638495, 3.488803631163671, 3.31256338697669, 2.9438676629025964, 0.4775672227574743, 0.43884455199774525, 0.42315888215551256, 0.4320230894212501, 0.42709741806266466, 0.4267072141430508, 0.41933942427899784, 0.41621361291223585, 0.41133734404507977, 0.40243010880293595, 0.4027349360213381, 0.3904245980089252, 0.40166610750237436, 0.3952568983974585, 0.38756254526377687, 0.41987720867142225, 0.7030593171864032, 0.39652414675904846, 0.3980426920878831, 0.39481036884509907, 0.3978817878336717, 0.3931412909114964, 0.3982205253819921, 0.38940718361113186, 0.39820926548045527, 0.920630136196851, 0.6796264954610554, 0.37599149424368, 0.37308649189731014, 0.36887554997316463, 0.8114623341654228, 0.9012797210927228, 1.8536694676390968, 1.232068980680949, 0.5893017598380603, 0.7861170534328835, 0.6210317443677627, 0.6114898791299533, 3.913575605326864, 10.023554943032465, 1.542254135710412, 2.908994255777829, 1.642914833942707, 2.189450285991189, 2.0140930207176155, 0.9310922828535353, 4.148771383624969, 1.1156879968998408, 1.0149908280815938, 1.7989619167069706, 0.9301408081111454, 2.0480750378047996, 4.032820836358293, 2.029247646433309, 2.157947223746286, 2.929340662729263, 2.6804319441131597, 2.5274987596875818, 1.5974622428222252, 1.4103403398223189, 1.646771415531713, 1.5739702739574821, 1.6496758953768516, 1.621315782539101, 1.5252162065562396, 1.428744400696125, 1.7994524408630144, 1.3358353217324737, 1.4166309411477058, 1.3031669772412897, 0.010176456123635722, 0.017076235992148726, 0.017746776889147466, 0.010173316513285348, 0.009781292260343744, 0.009969336073694473, 0.010065092693616074, 0.009690966762471791, 0.016277253770335006, 0.009073495601171613, 0.009322995155666057, 0.00910059063294477, 0.009161045707426072, 0.015600849475254579, 0.008878408231298771, 0.00918598085480383, 0.008950293940509736, 0.009416517102951421, 0.009091776090879617, 0.009119234593503245, 0.008904666382656952, 0.008816958473214325, 0.008800865539550829, 0.008747284252284937, 0.008536978971166401, 0.008638428471980581, 0.00871319502422862, 0.008587682406924852, 0.016664124365600472, 0.00862312305849311, 0.49271503004401385, 0.01408892740694631, 0.05244421881831203, 0.013304922278242785, 0.026660194991747266, 0.016084602253466255, 0.04241408065269877, 0.03733558815013198, 0.15036835153587538, 0.06554863232710363, 0.027926521451732828, 0.0504949859735876, 0.038042247280160965, 0.08000925579524941, 0.027150090876061364, 0.019406392271227202, 0.06960768332727961, 0.05012829324570019, 0.05564190074193215, 0.03908676976699917, 0.09075912009233085, 0.037688528816294115, 0.10448802737823731, 0.05288663015275334, 0.051711575261886335, 0.04872222047041459, 0.027551057558959955, 0.04895052204592595, 0.06863876876039887, 0.0570778888135529, 0.0360564699094335, 0.055140496443117915, 0.06538667091274512, 0.06069681400792757, 0.04876990246124319, 0.04370075250572187, 0.04000165431716899, 0.04802652828802207, 0.04001928938435856, 0.04180729373948469, 0.04222873145966543, 0.040574026673479105, 0.03980105430606399], \"Total\": [333.0, 178.0, 159.0, 114.0, 98.0, 83.0, 68.0, 88.0, 90.0, 58.0, 54.0, 43.0, 65.0, 50.0, 49.0, 26.0, 48.0, 61.0, 67.0, 39.0, 39.0, 46.0, 47.0, 41.0, 28.0, 55.0, 28.0, 47.0, 45.0, 52.0, 5.9954509018506235, 5.982663816953941, 5.964616537691784, 5.961878295026752, 5.948200764461356, 5.902106663819475, 5.870623218555143, 5.855154783910425, 5.861934862582453, 5.857855310646323, 5.83159875387578, 5.83667568740896, 5.819557030187187, 5.820947549183683, 5.8198162599890555, 5.820252098268437, 5.816028301643818, 5.799030883014869, 5.819873843695014, 5.818211830031193, 5.79612583078743, 5.817291431253727, 5.811350650613396, 5.814324579273282, 5.791726820842693, 5.785299593958047, 5.796398380314716, 5.792673585371641, 5.7872236486639235, 5.784713203942156, 12.889026158617053, 9.590268604273808, 8.602830800653303, 12.96750191097208, 13.058448755968733, 14.282246272916952, 90.87081478495062, 14.239290257537636, 43.99379640638286, 333.79811109031203, 26.156456425363217, 31.22761054474307, 178.4230525465709, 159.54805434559222, 88.58023299289027, 83.33420873855057, 61.54481130216787, 19.54883512975073, 29.234349832006284, 19.72161167016636, 47.48888311089475, 67.3629558886143, 23.4843821680969, 114.67041153304362, 65.04653069373757, 24.96700354558417, 33.21674719754759, 36.59720310188016, 98.23505065154029, 46.61801365862167, 32.47512464332266, 55.851975923809775, 48.54468879188193, 40.29636487644689, 45.46439147875622, 25.376222895124055, 61.396940905466096, 68.59307651358641, 52.113823112478535, 45.12258271043969, 28.99878775244185, 54.172958880866496, 4.459598756214862, 4.178237899643912, 4.368414152395713, 4.304621251721095, 4.243431092214984, 4.433611338382599, 4.115360462895908, 4.289811735821116, 4.36659386510238, 4.323301750530415, 4.46216324801938, 4.294492809453255, 4.179652050819159, 4.228418647733775, 4.377635391332813, 4.300733801257572, 4.213816932709157, 4.266058613740334, 4.178385582738719, 4.341341384801023, 4.270850704958111, 4.264479467636383, 4.29084214148436, 4.208659373289673, 4.193294726020557, 4.275828329863018, 4.178543011900012, 4.301453722370718, 4.282310510864584, 4.17929350397009, 4.4885203685981825, 7.0585856362455575, 10.265581178571498, 9.506832813923609, 7.094484322912043, 178.4230525465709, 20.624641360355483, 333.79811109031203, 49.710478361665004, 114.67041153304362, 88.58023299289027, 83.33420873855057, 67.3629558886143, 9.130764013765175, 47.74211637618906, 54.172958880866496, 26.560697857505225, 65.04653069373757, 21.605972492852853, 40.29636487644689, 43.99379640638286, 58.03709024925901, 41.94074071434754, 28.294025071170225, 20.742796192619334, 48.496798226285776, 159.54805434559222, 17.356488195006875, 27.64375232836932, 52.113823112478535, 14.948408639588498, 34.47752025004959, 45.46439147875622, 98.23505065154029, 27.99192755734169, 20.211176598071855, 39.0679800024248, 55.851975923809775, 29.57488671343022, 50.31693194575932, 61.54481130216787, 68.59307651358641, 90.87081478495062, 41.583322146209724, 61.396940905466096, 48.54468879188193, 9.727163427771254, 5.047768583926527, 5.310231962649394, 9.391480300148057, 5.247086665349963, 5.006756835442731, 5.228179654700327, 5.209809255888879, 4.965073248873599, 5.106711008602203, 4.854592791116368, 5.080598028873382, 5.0837136743071465, 5.16479273508539, 5.061811134271405, 5.216296562797985, 6.11335496095792, 5.066342397213168, 4.844052206674101, 5.1621561733051395, 16.046220316060886, 4.801903614048967, 4.899286658527549, 4.972145130193965, 5.119192991330085, 4.826566069034046, 10.18419527574524, 5.1803256675108065, 4.928398866947643, 12.901841557099988, 5.150051087404991, 28.21889832861721, 8.564223872124439, 8.61070238602735, 16.564345390203002, 16.39076925013136, 6.217231332457783, 13.022615252511773, 17.82494936964636, 6.0440385313727765, 18.6504061610232, 9.677722743557077, 48.496798226285776, 28.408953282733027, 39.822895224073804, 13.271949153879213, 10.332363419422549, 61.396940905466096, 28.7555713797925, 333.79811109031203, 28.026525649725023, 20.769216002319396, 159.54805434559222, 20.211176598071855, 33.21674719754759, 38.71139130349716, 18.544110795690703, 19.356596368641586, 98.23505065154029, 61.54481130216787, 47.74211637618906, 31.3525934322252, 114.67041153304362, 83.33420873855057, 55.851975923809775, 50.31693194575932, 67.3629558886143, 52.113823112478535, 45.12258271043969, 88.58023299289027, 178.4230525465709, 54.172958880866496, 90.87081478495062, 65.04653069373757, 4.812091504907326, 4.851491835794258, 4.9196535201019165, 4.843963335354435, 4.876130270498397, 4.898451706581906, 4.808134082398991, 4.982644053543488, 4.88450207816896, 4.931121903805276, 4.771205819182799, 4.940930687374594, 4.912872173564929, 5.015475481908349, 3.5092022850300606, 8.271626409402295, 7.43098859088599, 7.4872062662865, 4.272279094953993, 4.268672382750242, 14.1517689403079, 8.210718856084272, 4.295165470783088, 4.277002875584266, 4.27322466552273, 4.282437855819482, 12.089888446266608, 4.213422377037373, 16.239964340860617, 5.7660184320581225, 11.156575427797684, 10.972047457230014, 8.444080205853698, 21.605972492852853, 10.945022703526975, 25.67701057112438, 13.461303162510514, 16.039738741955286, 178.4230525465709, 18.398599999955888, 159.54805434559222, 114.67041153304362, 98.23505065154029, 20.742796192619334, 333.79811109031203, 67.3629558886143, 65.04653069373757, 25.882371835403745, 58.03709024925901, 68.59307651358641, 47.48888311089475, 90.87081478495062, 31.3525934322252, 46.61801365862167, 83.33420873855057, 54.172958880866496, 41.583322146209724, 61.396940905466096, 88.58023299289027, 19.36599450775398, 38.74544555644995, 45.12258271043969, 31.538045376897784, 49.710478361665004, 55.851975923809775, 48.54468879188193, 61.54481130216787, 5.201354207228511, 5.165503632658295, 5.22670565313333, 5.172085432554092, 5.185522437702544, 5.196527339053001, 5.191222499790892, 5.182175120715504, 5.147748340078515, 7.9707915178623105, 5.140157997488734, 5.171464156946125, 5.100944385029129, 5.266855060413195, 8.960804049039558, 14.536577364356653, 8.740212248996341, 9.316128500838634, 3.8547963131446386, 8.381474635985079, 3.8315944977111536, 8.550567793264984, 3.807667856654527, 3.8008261381374218, 3.800168561357178, 4.609407874349414, 11.41494175547901, 3.769486656630014, 3.767108063889779, 7.32810641568953, 12.056466835048036, 15.77402397154999, 11.658352652508889, 46.61801365862167, 68.59307651358641, 333.79811109031203, 114.67041153304362, 61.396940905466096, 21.227786649512048, 31.20975311054642, 50.31693194575932, 178.4230525465709, 47.48888311089475, 45.12258271043969, 159.54805434559222, 54.172958880866496, 27.250965139995888, 25.882371835403745, 98.23505065154029, 90.87081478495062, 45.46439147875622, 47.74211637618906, 88.58023299289027, 58.03709024925901, 49.710478361665004, 52.113823112478535, 28.99878775244185, 34.47752025004959, 48.54468879188193, 48.496798226285776, 55.851975923809775, 38.71139130349716, 39.822895224073804, 3.1955534134524908, 3.195963693990973, 3.2076073944758763, 5.657683375204376, 3.237834944083029, 3.2459751782599358, 3.2663926952100413, 3.2606187065128243, 3.275810818679052, 3.276061805228242, 3.2828447325507115, 3.327447893982976, 3.326304823340379, 3.351216667433303, 5.199192654772067, 3.0835321546360412, 3.1085177289781845, 5.116882836395807, 4.919537944545972, 4.996606837236445, 3.078467036022101, 3.1573291309303513, 2.997808280254777, 3.5092022850300606, 3.0498702968418074, 3.057399524228544, 3.031502035734171, 3.109495622159761, 2.9944640727186704, 3.007612424239122, 5.35932318920926, 26.101753908146968, 8.321442031271546, 58.03709024925901, 22.760254396611238, 15.810727271376601, 12.049093107014794, 31.538045376897784, 333.79811109031203, 68.59307651358641, 98.23505065154029, 159.54805434559222, 178.4230525465709, 65.04653069373757, 83.33420873855057, 28.88246772802568, 20.60171811904307, 50.31693194575932, 49.710478361665004, 45.46439147875622, 61.54481130216787, 88.58023299289027, 40.29636487644689, 41.94074071434754, 114.67041153304362, 54.172958880866496, 67.3629558886143, 25.414416793434647, 55.851975923809775, 38.74544555644995, 31.20975311054642, 45.12258271043969, 30.904359301055937, 39.822895224073804, 52.113823112478535, 48.54468879188193, 61.396940905466096, 5.088704249962274, 5.044571079963683, 5.064432065771224, 4.828219981871696, 4.868600698525609, 4.935676023663486, 4.837979238368677, 8.823200056550105, 7.011209266456026, 8.204274207863522, 9.96392594122264, 8.487559798636722, 4.829463713712894, 4.687456059342249, 4.618135173598345, 4.602790635782045, 4.940420538962765, 4.952266216743023, 4.711032081465777, 4.986656157952567, 4.928900969301077, 4.644617200928721, 5.010331847053492, 5.000838397453667, 5.036848412418045, 4.7355717715213705, 4.709972615358287, 4.997076147548599, 4.883251833051526, 4.794637909992555, 22.34035331113813, 16.887855286892222, 8.397535556330373, 8.638013344404184, 24.614294960768298, 15.334126434869836, 35.56461777228513, 15.977286598655013, 8.853082824855926, 159.54805434559222, 29.57488671343022, 333.79811109031203, 14.7679368461977, 16.01990422122595, 12.089888446266608, 29.138039603826304, 68.59307651358641, 55.851975923809775, 48.54468879188193, 114.67041153304362, 58.03709024925901, 48.496798226285776, 52.113823112478535, 90.87081478495062, 88.58023299289027, 178.4230525465709, 98.23505065154029, 61.54481130216787, 41.94074071434754, 39.822895224073804, 83.33420873855057, 47.74211637618906, 41.583322146209724, 31.8049271387818, 47.48888311089475, 67.3629558886143, 26.71193308196999, 38.71139130349716, 50.31693194575932, 3.7291507330187845, 3.7340975168998134, 3.7408769791155545, 3.7491884124625807, 3.7566512384960613, 3.7576735686451297, 3.767108063889779, 3.769486656630014, 3.800168561357178, 3.8008261381374218, 3.807667856654527, 3.8315944977111536, 3.8547963131446386, 7.291609444026536, 4.07691064985348, 4.051449090377915, 7.32810641568953, 4.112329480007475, 4.113405183127232, 4.106628428855701, 4.09007397070827, 4.073083317755048, 4.110244487506437, 4.136866629470825, 4.116731149120958, 4.144429615567327, 4.170008713590489, 7.43098859088599, 4.202251402276079, 4.158906207499075, 7.4872062662865, 13.176284728045118, 27.250965139995888, 7.9707915178623105, 10.242899419541729, 98.23505065154029, 23.4843821680969, 28.408953282733027, 39.0679800024248, 11.156575427797684, 23.098852827081753, 34.47752025004959, 333.79811109031203, 178.4230525465709, 61.396940905466096, 16.898612167721666, 90.87081478495062, 46.61801365862167, 50.31693194575932, 114.67041153304362, 159.54805434559222, 31.3525934322252, 68.59307651358641, 24.514826634564088, 52.113823112478535, 61.54481130216787, 48.54468879188193, 19.36599450775398, 17.422204349672448, 54.172958880866496, 88.58023299289027, 65.04653069373757, 49.710478361665004, 21.51916017177698, 3.8827318331730902, 3.913384712913458, 3.8788126694957916, 3.97855444339647, 3.9530932305768745, 3.9866558851063805, 3.9997609457582755, 3.970224872661176, 3.934817897156831, 3.8969142404128765, 3.911153279159489, 3.8015968007135643, 3.9535506879865787, 3.9082480484783115, 3.842859508797103, 4.170264111782512, 6.997429712315687, 3.9493145846700646, 3.973729296669716, 3.945357200001147, 4.00222098415424, 3.9611187329241475, 4.041909744582555, 3.9587798587167446, 4.108711956198641, 9.511404882400402, 7.0585856362455575, 3.96978307893351, 3.941193765002559, 3.9945518536645195, 8.858912583776638, 10.265581178571498, 23.104975762256544, 14.895922215268085, 6.544987085485084, 9.506832813923609, 7.094484322912043, 6.99582715280523, 83.33420873855057, 333.79811109031203, 26.101753908146968, 68.59307651358641, 31.8049271387818, 50.31693194575932, 48.496798226285776, 14.744175036374562, 159.54805434559222, 19.72161167016636, 17.191726747161493, 43.99379640638286, 14.948408639588498, 55.851975923809775, 178.4230525465709, 58.03709024925901, 65.04653069373757, 114.67041153304362, 98.23505065154029, 88.58023299289027, 39.822895224073804, 32.47512464332266, 47.74211637618906, 45.46439147875622, 54.172958880866496, 52.113823112478535, 47.48888311089475, 41.583322146209724, 90.87081478495062, 49.710478361665004, 67.3629558886143, 48.54468879188193, 2.9090963835399055, 4.919537944545972, 5.150854532250008, 2.9567280359886285, 2.8454703665996783, 2.9282521353849797, 3.0180454474379617, 2.9651870728662457, 4.996606837236445, 2.914996069776323, 3.0089276086617067, 2.969583570750195, 2.9973504036531073, 5.116882836395807, 2.924935398901915, 3.0309142340999826, 2.9690210851338494, 3.1246001499744245, 3.0509328944622753, 3.0639786978091768, 3.0063393994406318, 2.9799901345273505, 2.99115117726961, 2.994485484520553, 2.9577097363593214, 2.997717072900842, 3.061616920527064, 3.020940839400128, 5.87246019825812, 3.0444406140184177, 333.79811109031203, 5.35932318920926, 26.101753908146968, 5.199192654772067, 12.848475220985152, 6.688257427421436, 26.777251493048627, 23.037435548873756, 178.4230525465709, 54.172958880866496, 16.055893763326566, 39.822895224073804, 26.122634581150944, 83.33420873855057, 15.810727271376601, 9.469590491807761, 68.59307651358641, 41.94074071434754, 49.710478361665004, 29.138039603826304, 114.67041153304362, 28.21889832861721, 159.54805434559222, 50.31693194575932, 48.496798226285776, 43.99379640638286, 17.191726747161493, 47.74211637618906, 88.58023299289027, 65.04653069373757, 28.294025071170225, 67.3629558886143, 98.23505065154029, 90.87081478495062, 58.03709024925901, 46.61801365862167, 38.71139130349716, 61.396940905466096, 39.0679800024248, 45.12258271043969, 55.851975923809775, 45.46439147875622, 52.113823112478535], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.3662, -6.37, -6.3752, -6.3761, -6.3805, -6.5387, -6.5834, -6.5928, -6.5983, -6.6077, -6.6313, -6.631, -6.6351, -6.6449, -6.6513, -6.6519, -6.6584, -6.6626, -6.6618, -6.6643, -6.67, -6.6678, -6.6712, -6.671, -6.6776, -6.6818, -6.6832, -6.6886, -6.6914, -6.6939, -5.9178, -6.214, -6.3203, -5.9694, -5.9851, -5.9098, -4.3462, -5.925, -4.999, -3.4662, -5.4851, -5.3658, -4.1076, -4.2632, -4.6966, -4.8058, -5.0681, -5.8453, -5.5912, -5.8587, -5.3441, -5.1858, -5.7983, -4.9038, -5.2397, -5.7687, -5.6262, -5.5975, -5.1548, -5.5065, -5.6639, -5.4525, -5.5135, -5.6235, -5.5891, -5.7765, -5.5512, -5.5535, -5.656, -5.6853, -5.7697, -5.767, -6.9201, -7.0198, -6.9811, -6.9989, -7.0145, -6.9836, -7.0604, -7.0267, -7.012, -7.0277, -7.0078, -7.0628, -7.0915, -7.0811, -7.0533, -7.0723, -7.0936, -7.0846, -7.1058, -7.0696, -7.0861, -7.0937, -7.0881, -7.1195, -7.1297, -7.1188, -7.1479, -7.1223, -7.1368, -7.1677, -7.0997, -6.6906, -6.37, -6.4613, -6.705, -4.1093, -5.8508, -3.6309, -5.1515, -4.5084, -4.7755, -4.888, -5.0452, -6.5258, -5.3267, -5.2382, -5.7585, -5.151, -5.9314, -5.4998, -5.4436, -5.2589, -5.4947, -5.7673, -5.9973, -5.4455, -4.6727, -6.119, -5.8329, -5.4406, -6.22, -5.7109, -5.5445, -5.1255, -5.8542, -6.0452, -5.69, -5.5501, -5.8644, -5.6176, -5.5395, -5.4961, -5.3982, -5.7158, -5.6108, -5.7145, -6.0556, -6.7295, -6.6859, -6.1277, -6.7178, -6.7784, -6.739, -6.7505, -6.8008, -6.7912, -6.8423, -6.7994, -6.8024, -6.7871, -6.8103, -6.7815, -6.6239, -6.8127, -6.8632, -6.8017, -5.6681, -6.8777, -6.859, -6.8461, -6.8198, -6.8788, -6.1348, -6.8107, -6.8615, -5.8992, -6.8183, -5.175, -6.3353, -6.3312, -5.7466, -5.7694, -6.6468, -6.001, -5.7389, -6.6753, -5.7827, -6.3016, -5.1491, -5.5468, -5.3621, -6.1316, -6.3051, -5.1095, -5.6297, -4.0018, -5.6949, -5.888, -4.6368, -5.9108, -5.6256, -5.5585, -5.9818, -5.9737, -5.1029, -5.3702, -5.531, -5.7348, -5.165, -5.3261, -5.5018, -5.5534, -5.4443, -5.5743, -5.6448, -5.4488, -5.2685, -5.7008, -5.6558, -5.6876, -6.3675, -6.3732, -6.3728, -6.3963, -6.4045, -6.4084, -6.435, -6.408, -6.4318, -6.4236, -6.4762, -6.4441, -6.4722, -6.4963, -7.0469, -6.2527, -6.371, -6.3734, -6.939, -6.9485, -5.7653, -6.3099, -6.9643, -6.9709, -6.9737, -6.9934, -5.956, -7.0142, -5.671, -6.713, -6.0594, -6.0799, -6.375, -5.5601, -6.1591, -5.4661, -6.0024, -5.8868, -3.9963, -5.7949, -4.2839, -4.5555, -4.6956, -5.7351, -4.0438, -5.0451, -5.0725, -5.6146, -5.1977, -5.1286, -5.3499, -5.0484, -5.6042, -5.4548, -5.2324, -5.4277, -5.5413, -5.4121, -5.2799, -5.8577, -5.6013, -5.5547, -5.7077, -5.5852, -5.5949, -5.7551, -5.7479, -6.3708, -6.3911, -6.3934, -6.445, -6.4524, -6.451, -6.4697, -6.4805, -6.5221, -6.0869, -6.5489, -6.5473, -6.6583, -6.6379, -6.166, -5.7135, -6.2759, -6.306, -7.205, -6.4603, -7.2603, -6.4764, -7.3218, -7.3399, -7.3406, -7.157, -6.2961, -7.427, -7.4342, -6.7717, -6.303, -6.0672, -6.3614, -5.1469, -4.9385, -3.6537, -4.5331, -5.078, -5.9242, -5.6819, -5.3664, -4.5449, -5.4058, -5.4526, -4.7371, -5.3723, -5.7863, -5.8208, -5.2624, -5.3411, -5.6276, -5.6136, -5.4183, -5.6025, -5.6594, -5.6648, -5.8608, -5.8071, -5.7185, -5.7356, -5.7024, -5.8468, -5.8786, -6.6234, -6.625, -6.6325, -6.0687, -6.6468, -6.6486, -6.6624, -6.6647, -6.666, -6.6696, -6.6687, -6.7, -6.7011, -6.7116, -6.4381, -7.0061, -7.0045, -6.5092, -6.5485, -6.5356, -7.0206, -7.0045, -7.0594, -6.9079, -7.052, -7.0509, -7.0715, -7.0591, -7.0994, -7.1056, -6.5289, -5.1098, -6.1723, -4.5108, -5.4224, -5.7468, -5.9692, -5.396, -3.7948, -4.8802, -4.644, -4.4568, -4.3855, -5.0517, -4.9292, -5.5606, -5.7692, -5.341, -5.3555, -5.422, -5.3, -5.1393, -5.512, -5.5103, -5.0964, -5.425, -5.3383, -5.7603, -5.4384, -5.5971, -5.7657, -5.6616, -5.7853, -5.7452, -5.7149, -5.7275, -5.7454, -6.1499, -6.1657, -6.1869, -6.2715, -6.2703, -6.2752, -6.356, -5.9045, -6.1651, -6.2206, -6.0959, -6.2838, -6.8933, -6.9362, -6.9513, -6.9629, -6.8973, -6.8962, -6.9503, -6.9062, -6.9295, -6.9968, -6.9281, -6.9322, -6.9305, -6.9937, -7.0035, -6.9528, -6.9764, -6.9961, -5.4792, -5.7598, -6.4496, -6.4392, -5.489, -5.9416, -5.2224, -5.9526, -6.4661, -4.1832, -5.5492, -3.8174, -6.1087, -6.0539, -6.2681, -5.6906, -5.1291, -5.3079, -5.4065, -4.9156, -5.3583, -5.4615, -5.4484, -5.1605, -5.2354, -5.1321, -5.4077, -5.5732, -5.6958, -5.7106, -5.5577, -5.6992, -5.7815, -5.8361, -5.7715, -5.7692, -5.9074, -5.8889, -5.9004, -5.9235, -5.9262, -5.9299, -5.9348, -5.939, -5.9392, -5.9445, -5.9459, -5.9634, -5.9633, -5.9672, -5.9811, -5.9944, -5.7328, -6.3768, -6.3948, -5.8033, -6.4021, -6.4176, -6.4282, -6.4374, -6.4426, -6.4344, -6.4451, -6.4563, -6.4727, -6.4678, -5.907, -6.4829, -6.5323, -5.9903, -5.4744, -4.8879, -5.9415, -5.7531, -4.1271, -5.1899, -5.0801, -4.8607, -5.7963, -5.3555, -5.1268, -3.83, -4.2487, -4.9187, -5.6227, -4.9505, -5.2271, -5.2184, -4.9439, -4.8771, -5.3892, -5.2788, -5.5244, -5.3669, -5.3518, -5.421, -5.6182, -5.6501, -5.4777, -5.4212, -5.4801, -5.5319, -5.6499, -6.8457, -6.9302, -6.9666, -6.9459, -6.9574, -6.9583, -6.9757, -6.9832, -6.995, -7.0169, -7.0161, -7.0472, -7.0188, -7.0349, -7.0545, -6.9744, -6.4589, -7.0317, -7.0278, -7.036, -7.0282, -7.0402, -7.0274, -7.0498, -7.0274, -6.1893, -6.4928, -7.0848, -7.0926, -7.1039, -6.3156, -6.2106, -5.4895, -5.8979, -6.6355, -6.3473, -6.583, -6.5985, -4.7422, -3.8017, -5.6734, -5.0388, -5.6102, -5.323, -5.4065, -6.178, -4.6838, -5.9972, -6.0918, -5.5194, -6.1791, -5.3897, -4.7122, -5.399, -5.3375, -5.0319, -5.1207, -5.1794, -5.6382, -5.7628, -5.6078, -5.653, -5.6061, -5.6234, -5.6845, -5.7498, -5.5192, -5.8171, -5.7584, -5.8418, -7.1409, -6.6233, -6.5848, -7.1412, -7.1805, -7.1615, -7.1519, -7.1898, -6.6712, -7.2556, -7.2285, -7.2526, -7.246, -6.7137, -7.2774, -7.2433, -7.2693, -7.2185, -7.2536, -7.2506, -7.2744, -7.2843, -7.2861, -7.2922, -7.3166, -7.3048, -7.2961, -7.3107, -6.6477, -7.3065, -3.2611, -6.8156, -5.5012, -6.8728, -6.1778, -6.6831, -5.7135, -5.841, -4.4479, -5.2782, -6.1314, -5.5391, -5.8223, -5.0788, -6.1596, -6.4954, -5.2181, -5.5464, -5.442, -5.7952, -4.9528, -5.8316, -4.8119, -5.4928, -5.5153, -5.5748, -6.1449, -5.5702, -5.2321, -5.4166, -5.8759, -5.4511, -5.2807, -5.3551, -5.5739, -5.6836, -5.7721, -5.5892, -5.7716, -5.7279, -5.7179, -5.7579, -5.7771], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3841, 1.3825, 1.3804, 1.3798, 1.3777, 1.2273, 1.188, 1.1813, 1.1746, 1.1658, 1.1467, 1.1462, 1.1451, 1.135, 1.1288, 1.1281, 1.1223, 1.1211, 1.1183, 1.1161, 1.1142, 1.1127, 1.1104, 1.1101, 1.1074, 1.1042, 1.1009, 1.0962, 1.0943, 1.0922, 1.0672, 1.0666, 1.069, 1.0095, 0.9868, 0.9726, 0.6857, 0.9604, 0.7583, 0.2646, 0.7922, 0.7343, 0.2496, 0.2058, 0.3609, 0.3127, 0.3535, 0.7231, 0.5749, 0.701, 0.3368, 0.1455, 0.5867, -0.1045, 0.1266, 0.5552, 0.4122, 0.3439, -0.2008, 0.1929, 0.397, 0.0662, 0.1454, 0.2216, 0.1353, 0.531, -0.1272, -0.2403, -0.0681, 0.0467, 0.4044, -0.2178, 1.1262, 1.0917, 1.0859, 1.0828, 1.0815, 1.0685, 1.0663, 1.0584, 1.0554, 1.0497, 1.038, 1.0213, 1.0196, 1.0184, 1.0116, 1.0103, 1.0094, 1.006, 1.0056, 1.0036, 1.0034, 0.9973, 0.9968, 0.9847, 0.9782, 0.9696, 0.9635, 0.9602, 0.95, 0.9435, 0.9401, 0.8965, 0.8426, 0.8281, 0.8771, 0.248, 0.6641, 0.0999, 0.4836, 0.2909, 0.2819, 0.2305, 0.2861, 0.8039, 0.3488, 0.311, 0.5034, 0.2153, 0.537, 0.3453, 0.3137, 0.2214, 0.3104, 0.4315, 0.5118, 0.2143, -0.2037, 0.5684, 0.3891, 0.1473, 0.6168, 0.2902, 0.1799, -0.1715, 0.3553, 0.4899, 0.186, -0.0314, 0.2901, 0.0054, -0.1179, -0.1829, -0.3662, 0.0979, -0.1868, -0.0556, 1.2108, 1.1929, 1.1859, 1.1739, 1.1659, 1.1522, 1.1483, 1.1403, 1.1381, 1.1196, 1.1191, 1.1165, 1.1129, 1.1124, 1.1094, 1.108, 1.107, 1.106, 1.1004, 1.0983, 1.0978, 1.0946, 1.0933, 1.0914, 1.0886, 1.0884, 1.0858, 1.0858, 1.0848, 1.0848, 1.0841, 1.0264, 1.0585, 1.0572, 0.9875, 0.9752, 1.0673, 0.9737, 0.9218, 1.067, 0.8328, 0.97, 0.5107, 0.6479, 0.4948, 0.8241, 0.901, 0.3145, 0.5528, -0.271, 0.5133, 0.6199, -0.1678, 0.6243, 0.4127, 0.3267, 0.6394, 0.6046, -0.1489, 0.0514, 0.1445, 0.3613, -0.3657, -0.2076, 0.0169, 0.0696, -0.113, 0.0136, 0.0872, -0.3913, -0.9112, -0.1516, -0.6238, -0.3213, 1.6028, 1.5889, 1.5753, 1.5674, 1.5525, 1.5441, 1.5361, 1.5274, 1.5235, 1.5222, 1.5025, 1.4997, 1.4773, 1.4326, 1.239, 1.1758, 1.1648, 1.1547, 1.1502, 1.1416, 1.1263, 1.1261, 1.1196, 1.1172, 1.1153, 1.0935, 1.093, 1.0889, 1.0829, 1.0764, 1.0699, 1.0661, 1.0329, 0.9083, 0.9893, 0.8297, 0.9391, 0.8795, 0.3609, 0.8341, 0.1851, 0.2438, 0.2584, 0.7741, -0.313, 0.2861, 0.2938, 0.6732, 0.2826, 0.1846, 0.331, -0.0164, 0.4919, 0.2445, -0.1139, 0.1215, 0.2724, 0.0119, -0.2224, 0.7201, 0.2831, 0.1773, 0.3825, 0.05, -0.0763, -0.0962, -0.3263, 1.5217, 1.5082, 1.4942, 1.4531, 1.4431, 1.4423, 1.4247, 1.4156, 1.3808, 1.3786, 1.3553, 1.3509, 1.2537, 1.242, 1.1825, 1.1512, 1.0975, 1.0036, 0.9871, 0.9551, 0.9378, 0.919, 0.8826, 0.8663, 0.8657, 0.8563, 0.8104, 0.7874, 0.7809, 0.778, 0.7487, 0.7158, 0.7239, 0.5525, 0.3747, 0.0771, 0.2662, 0.346, 0.5618, 0.4187, 0.2566, -0.1877, 0.2751, 0.2794, -0.268, 0.1768, 0.45, 0.467, -0.3084, -0.3092, 0.0969, 0.062, -0.3608, -0.1222, -0.0242, -0.0769, 0.3133, 0.194, -0.0596, -0.0757, -0.1838, 0.0384, -0.0217, 1.7562, 1.7544, 1.7433, 1.7397, 1.7197, 1.7154, 1.6952, 1.6948, 1.6888, 1.6852, 1.6839, 1.6392, 1.6384, 1.6204, 1.4548, 1.4092, 1.4027, 1.3996, 1.3996, 1.397, 1.3963, 1.3872, 1.3841, 1.3781, 1.3742, 1.3729, 1.3608, 1.3478, 1.3452, 1.3346, 1.3336, 1.1696, 1.2502, 0.9695, 0.9939, 1.0339, 1.0832, 0.6941, -0.0639, 0.433, 0.31, 0.0122, -0.0283, 0.3146, 0.1893, 0.6175, 0.7468, 0.282, 0.2796, 0.3025, 0.1216, -0.0818, 0.3331, 0.2948, -0.2971, 0.1242, -0.007, 0.5457, 0.0803, 0.2872, 0.3349, 0.0704, 0.3251, 0.1118, -0.127, -0.0687, -0.3214, 1.7644, 1.7574, 1.7323, 1.6954, 1.6882, 1.6696, 1.6088, 1.4595, 1.4288, 1.2162, 1.1465, 1.119, 1.0734, 1.0603, 1.0601, 1.0518, 1.0466, 1.0453, 1.0412, 1.0284, 1.0168, 1.0089, 1.0017, 0.9996, 0.9941, 0.9926, 0.9882, 0.9798, 0.9791, 0.9778, 0.9558, 0.9549, 0.9638, 0.946, 0.8491, 0.8697, 0.7476, 0.8176, 0.8945, 0.2859, 0.6052, -0.0865, 0.7402, 0.7136, 0.7809, 0.4788, 0.1841, 0.2108, 0.2524, -0.1163, 0.122, 0.1984, 0.1396, -0.1286, -0.178, -0.7749, -0.4537, -0.1516, 0.1093, 0.1463, -0.4392, -0.0237, 0.0321, 0.2456, -0.0907, -0.4379, 0.3489, -0.0036, -0.2773, 2.3016, 2.2976, 2.2921, 2.2851, 2.2788, 2.2784, 2.2705, 2.2685, 2.243, 2.2428, 2.2372, 2.217, 2.1977, 1.8218, 1.7593, 1.7475, 1.7464, 1.7253, 1.7095, 1.7006, 1.6954, 1.6943, 1.6935, 1.6764, 1.6701, 1.6469, 1.6457, 1.6287, 1.6228, 1.5838, 1.5379, 1.4885, 1.3484, 1.524, 1.4616, 0.8269, 1.1952, 1.1145, 1.0154, 1.333, 1.0461, 0.8743, -0.0992, 0.1085, 0.5053, 1.0915, 0.0814, 0.4722, 0.4046, -0.1446, -0.4081, 0.7069, 0.0344, 0.8177, 0.221, 0.0698, 0.2379, 0.9597, 1.0335, 0.0715, -0.3638, -0.1138, 0.1032, 0.8225, 1.3391, 1.2467, 1.2192, 1.2145, 1.2095, 1.2001, 1.1794, 1.1794, 1.1765, 1.1643, 1.1614, 1.1588, 1.148, 1.1434, 1.1406, 1.139, 1.1369, 1.1362, 1.1338, 1.1328, 1.1263, 1.1246, 1.1173, 1.1157, 1.1008, 1.0995, 1.0943, 1.0778, 1.0773, 1.0525, 1.0444, 1.002, 0.9119, 0.9423, 1.0272, 0.9421, 0.999, 0.9976, 0.3763, -0.0709, 0.606, 0.2744, 0.4716, 0.3, 0.2534, 0.6725, -0.2148, 0.5625, 0.6052, 0.2379, 0.6577, 0.1289, -0.355, 0.0813, 0.0288, -0.2325, -0.1666, -0.1219, 0.2187, 0.2981, 0.0677, 0.0714, -0.0569, -0.0355, -0.0036, 0.0638, -0.4872, -0.1819, -0.4271, -0.183, 1.3326, 1.3249, 1.3174, 1.3161, 1.3151, 1.3055, 1.2848, 1.2646, 1.2614, 1.2159, 1.2113, 1.2003, 1.1976, 1.1952, 1.1907, 1.1892, 1.1838, 1.1835, 1.1723, 1.1711, 1.1662, 1.1651, 1.1596, 1.1524, 1.1404, 1.1388, 1.1263, 1.1251, 1.1234, 1.1215, 0.4698, 1.0469, 0.7781, 1.02, 0.8103, 0.9579, 0.5403, 0.5632, -0.0907, 0.271, 0.6339, 0.3178, 0.4563, 0.0397, 0.6211, 0.7979, 0.0951, 0.2587, 0.1931, 0.3741, -0.1535, 0.3697, -0.3429, 0.1302, 0.1446, 0.1825, 0.552, 0.1054, -0.1747, -0.0503, 0.3228, -0.1198, -0.3267, -0.3232, -0.0936, 0.0158, 0.1132, -0.1652, 0.1044, 0.0041, -0.1992, -0.0334, -0.1892]}, \"token.table\": {\"Topic\": [1, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 6, 1, 4, 5, 1, 2, 3, 4, 5, 6, 8, 9, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 2, 3, 2, 2, 3, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 7, 4, 5, 8, 2, 3, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 7, 2, 6, 1, 2, 6, 1, 2, 3, 4, 6, 7, 8, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 7, 8, 9, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 8, 2, 3, 2, 3, 2, 6, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 9, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 8, 2, 3, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 2, 3, 1, 2, 3, 7, 2, 3, 4, 6, 7, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 2, 3, 1, 2, 5, 6, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 4, 5, 8, 4, 6, 7, 5, 8, 2, 5, 6, 6, 1, 2, 1, 2, 3, 5, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 9, 1, 3, 4, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 2, 3, 1, 2, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 9, 2, 3, 1, 2, 3, 7, 6, 1, 2, 3, 4, 5, 2, 2, 5, 2, 3, 5, 6, 9, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 8, 1, 3, 4, 1, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 8, 5, 8, 2, 3, 1, 1, 3, 4, 2, 3, 5, 8, 1, 2, 4, 5, 6, 7, 8, 2, 3, 6, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 6, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 4, 5, 1, 3, 4, 1, 2, 3, 7, 2, 4, 6, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 5, 6, 8, 9, 4, 5, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 2, 4, 5, 6, 7, 9, 1, 2, 5, 7, 1, 2, 1, 1, 1, 2, 3, 4, 6, 7, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 1, 2, 3, 4, 5, 6, 7, 9, 4, 8, 1, 2, 3, 4, 5, 2, 3, 1, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 1, 2, 3, 4, 6, 9, 2, 5, 6, 1, 2, 3, 4, 5, 6, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 6, 2, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 5, 6, 9, 2, 5, 1, 2, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 4, 2, 6, 1, 2, 3, 4, 6, 7, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 3, 4, 5, 6, 2, 3, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 6, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 2, 6, 2, 3, 1, 2, 3, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 6, 1, 2, 2, 6, 5, 8, 1, 2, 3, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 8, 2, 3, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 8, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 2, 3, 1, 2, 4, 4, 5, 8, 1, 2, 3, 7, 1, 2, 3, 7, 1, 3, 4, 4, 5, 8, 1, 3, 4, 2, 3, 2, 6, 5, 8, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 2, 3, 1, 2, 2, 1, 2, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 6, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 2, 3, 4, 5, 8, 1, 4, 5, 8, 5, 8, 1, 5, 8, 2, 3, 5, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 1, 2, 3, 7, 1, 3, 4, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 4, 5, 2, 3, 5, 6, 2, 3, 6, 2, 3, 2, 4, 5, 6, 7, 8, 2, 3, 2, 3, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 7, 1, 2, 3, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 6, 1, 2, 1, 2, 1, 2, 3, 4, 5, 6, 7, 4, 6, 7, 2, 5, 1, 4, 5, 4, 5, 8, 4, 5, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 7, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 6, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 1, 4, 5, 1, 2, 3, 4, 6, 7, 6, 1, 2, 5, 6, 7, 5, 8, 1, 2, 3, 4, 5, 5, 8, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 3, 4, 1, 2, 3, 7, 1, 4, 5, 1, 2, 3, 7, 5, 8, 2, 3, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 2, 3, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 5, 6, 7, 8, 1, 2, 1, 4, 5, 2, 3, 6, 6, 1, 2, 3, 4, 6, 7, 6, 2, 6, 1, 2, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 7, 1, 4, 5, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 7, 2, 6, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 6, 7, 8, 4, 6, 7, 1, 4, 6, 8, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 6, 2, 3, 1, 4, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 5, 6, 9, 2, 3, 2, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 1, 2, 1, 2, 3, 4, 6, 7, 8, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 7, 2, 5, 4, 5, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 7, 8, 9, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 4, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 2, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"Freq\": [0.2368523215368724, 0.1184261607684362, 0.3552784823053086, 0.1184261607684362, 0.1184261607684362, 0.16906235511392356, 0.2028748261367083, 0.033812471022784715, 0.16906235511392356, 0.10143741306835415, 0.10143741306835415, 0.13524988409113886, 0.033812471022784715, 0.033812471022784715, 0.4657127369261159, 0.23285636846305796, 0.3200409498822386, 0.19284459994411904, 0.3856891998882381, 0.3856891998882381, 0.3762696985980856, 0.20523801741713762, 0.13682534494475843, 0.034206336236189606, 0.034206336236189606, 0.06841267247237921, 0.06841267247237921, 0.034206336236189606, 0.3066902603492338, 0.6133805206984676, 0.4587777413290556, 0.15292591377635187, 0.03823147844408797, 0.07646295688817593, 0.07646295688817593, 0.07646295688817593, 0.03823147844408797, 0.03823147844408797, 0.03823147844408797, 0.3080738283821592, 0.6161476567643184, 0.4482130950470582, 0.2241065475235291, 0.24740780056761982, 0.4785087312729837, 0.23925436563649186, 0.6831587118741478, 0.17078967796853695, 0.22161852002514856, 0.11080926001257428, 0.17729481602011885, 0.13297111201508913, 0.11080926001257428, 0.08864740801005942, 0.06648555600754456, 0.04432370400502971, 0.022161852002514856, 0.13542853147526426, 0.2031427972128964, 0.06771426573763213, 0.13542853147526426, 0.06771426573763213, 0.06771426573763213, 0.2031427972128964, 0.06771426573763213, 0.44832120536218206, 0.16011471620077933, 0.09606882972046758, 0.12809177296062346, 0.06404588648031173, 0.032022943240155866, 0.032022943240155866, 0.032022943240155866, 0.032022943240155866, 0.6872554543109956, 0.1718138635777489, 0.1923375543859011, 0.1923375543859011, 0.1923375543859011, 0.3846751087718022, 0.1923375543859011, 0.2034701834859435, 0.2034701834859435, 0.135646788990629, 0.0678233944953145, 0.135646788990629, 0.0678233944953145, 0.0678233944953145, 0.0678233944953145, 0.0678233944953145, 0.21231545948679156, 0.21231545948679156, 0.21231545948679156, 0.21231545948679156, 0.4670237064344469, 0.23351185321722345, 0.23351185321722345, 0.4746290671707362, 0.2373145335853681, 0.47695192698701694, 0.23847596349350847, 0.11613454456662065, 0.2322690891332413, 0.4645381782664826, 0.11613454456662065, 0.2066601878351491, 0.10333009391757456, 0.4133203756702982, 0.10333009391757456, 0.10333009391757456, 0.10333009391757456, 0.30524454648691535, 0.6104890929738307, 0.6823685513007927, 0.17059213782519816, 0.3215955645261306, 0.19356655576404175, 0.09678327788202087, 0.3871331115280835, 0.09678327788202087, 0.09678327788202087, 0.09678327788202087, 0.09678327788202087, 0.19823290903202007, 0.19823290903202007, 0.39646581806404013, 0.27861152268425515, 0.17375772382458926, 0.11683709015791346, 0.08687886191229463, 0.09886215321054216, 0.08088721626317086, 0.07489557061404709, 0.0539248108421139, 0.029958228245618838, 0.3546627107271081, 0.1182209035757027, 0.19703483929283783, 0.07881393571713513, 0.07881393571713513, 0.039406967858567565, 0.039406967858567565, 0.039406967858567565, 0.039406967858567565, 0.22959207226123504, 0.17219405419592626, 0.17219405419592626, 0.11479603613061752, 0.05739801806530876, 0.05739801806530876, 0.17219405419592626, 0.05739801806530876, 0.1968272227633307, 0.3936544455266614, 0.1391034783197156, 0.1738793478996445, 0.2782069566394312, 0.1738793478996445, 0.0695517391598578, 0.10432760873978669, 0.0695517391598578, 0.0347758695799289, 0.24682526614365555, 0.24682526614365555, 0.24682526614365555, 0.24358403144177426, 0.12179201572088713, 0.12179201572088713, 0.36537604716266137, 0.12179201572088713, 0.12179201572088713, 0.154910712114414, 0.10327380807627601, 0.051636904038138004, 0.25818452019069005, 0.10327380807627601, 0.154910712114414, 0.051636904038138004, 0.154910712114414, 0.051636904038138004, 0.2452837665294281, 0.2452837665294281, 0.4510995320418882, 0.2255497660209441, 0.4786537672019014, 0.2393268836009507, 0.2556790615516099, 0.2556790615516099, 0.4037147902069801, 0.13457159673566002, 0.26914319347132004, 0.09256699741988425, 0.2777009922596527, 0.09256699741988425, 0.2777009922596527, 0.046283498709942125, 0.09256699741988425, 0.046283498709942125, 0.046283498709942125, 0.19127116244005943, 0.5738134873201782, 0.19651368027674504, 0.19651368027674504, 0.3930273605534901, 0.6206830447505564, 0.07758538059381954, 0.07758538059381954, 0.07758538059381954, 0.07758538059381954, 0.07758538059381954, 0.19582075396777104, 0.3916415079355421, 0.33248964924494356, 0.32776859884892656, 0.12371950766737291, 0.20619917944562152, 0.26805893327930796, 0.06185975383368646, 0.08247967177824861, 0.08247967177824861, 0.10309958972281076, 0.041239835889124304, 0.041239835889124304, 0.20112043671601149, 0.40224087343202297, 0.19170689165410623, 0.38341378330821246, 0.19996646972419288, 0.19996646972419288, 0.19996646972419288, 0.19996646972419288, 0.20140689771834985, 0.4028137954366997, 0.1974555067603059, 0.1974555067603059, 0.3949110135206118, 0.44558113493080204, 0.22279056746540102, 0.1063117335433912, 0.1417489780578549, 0.4252469341735648, 0.03543724451446373, 0.1063117335433912, 0.07087448902892746, 0.03543724451446373, 0.07087448902892746, 0.03543724451446373, 0.19318167715837561, 0.11590900629502537, 0.11590900629502537, 0.23181801259005075, 0.15454534172670048, 0.11590900629502537, 0.03863633543167512, 0.03863633543167512, 0.333627993170642, 0.1745025409094131, 0.1745025409094131, 0.23267005454588416, 0.05816751363647104, 0.11633502727294208, 0.11633502727294208, 0.05816751363647104, 0.05816751363647104, 0.05816751363647104, 0.19194560700464333, 0.57583682101393, 0.12188768618210415, 0.12188768618210415, 0.12188768618210415, 0.2437753723642083, 0.12188768618210415, 0.12188768618210415, 0.2437753723642083, 0.21643292395820135, 0.1683367186341566, 0.12024051331011187, 0.1683367186341566, 0.09619241064808949, 0.09619241064808949, 0.07214430798606712, 0.048096205324044745, 0.024048102662022373, 0.23203524911245593, 0.20303084297339893, 0.05800881227811398, 0.11601762455622797, 0.11601762455622797, 0.05800881227811398, 0.02900440613905699, 0.14502203069528496, 0.02900440613905699, 0.3372468500051053, 0.45686765141741986, 0.22843382570870993, 0.2858847076000195, 0.2858847076000195, 0.14294235380000975, 0.14294235380000975, 0.14294235380000975, 0.3380994381250242, 0.23608647205117023, 0.19673872670930853, 0.0786954906837234, 0.11804323602558511, 0.0786954906837234, 0.1573909813674468, 0.0393477453418617, 0.0786954906837234, 0.0393477453418617, 0.11493480516892123, 0.15324640689189498, 0.038311601722973744, 0.15324640689189498, 0.11493480516892123, 0.2681812120608162, 0.11493480516892123, 0.038311601722973744, 0.07662320344594749, 0.2066978692403796, 0.2066978692403796, 0.4133957384807592, 0.21704723471431617, 0.21704723471431617, 0.1446981564762108, 0.0723490782381054, 0.10852361735715808, 0.10852361735715808, 0.0361745391190527, 0.0723490782381054, 0.0361745391190527, 0.09641901609733969, 0.24104754024334923, 0.09641901609733969, 0.24104754024334923, 0.048209508048669844, 0.14462852414600955, 0.048209508048669844, 0.048209508048669844, 0.24291117485617908, 0.24291117485617908, 0.24291117485617908, 0.14262874805125772, 0.28525749610251544, 0.28525749610251544, 0.26262794908761156, 0.5252558981752231, 0.25296645985100386, 0.25296645985100386, 0.3326304409229586, 0.3339471856415126, 0.6853216135734442, 0.17133040339336106, 0.11676481312625242, 0.11676481312625242, 0.4670592525050097, 0.11676481312625242, 0.19543148279399977, 0.19543148279399977, 0.19543148279399977, 0.39086296558799954, 0.19543148279399977, 0.2174078462496924, 0.1087039231248462, 0.0543519615624231, 0.2717598078121155, 0.1087039231248462, 0.0543519615624231, 0.0543519615624231, 0.0543519615624231, 0.4699272659214822, 0.1342649331204235, 0.06713246656021175, 0.06713246656021175, 0.06713246656021175, 0.06713246656021175, 0.06713246656021175, 0.06713246656021175, 0.20508065710430423, 0.20508065710430423, 0.6152419713129127, 0.19359196529794626, 0.19359196529794626, 0.3871839305958925, 0.07040034105077714, 0.14080068210155428, 0.28160136420310855, 0.07040034105077714, 0.10560051157616572, 0.07040034105077714, 0.03520017052538857, 0.17600085262694287, 0.03520017052538857, 0.32430341240207794, 0.47854978313921104, 0.23927489156960552, 0.6911777119454277, 0.1727944279863569, 0.25320849442626575, 0.25320849442626575, 0.25320849442626575, 0.24194759111952222, 0.19795712000688181, 0.10997617778160101, 0.0879809422252808, 0.10997617778160101, 0.10997617778160101, 0.0659857066689606, 0.0439904711126404, 0.0439904711126404, 0.12061252502384667, 0.1895339678946162, 0.05169108215307715, 0.15507324645923143, 0.0861518035884619, 0.22399468933000097, 0.0861518035884619, 0.03446072143538476, 0.03446072143538476, 0.4606871062943755, 0.23034355314718774, 0.20327112246560602, 0.20327112246560602, 0.20327112246560602, 0.40654224493121205, 0.07066254432346908, 0.14132508864693816, 0.07066254432346908, 0.3533127216173454, 0.07066254432346908, 0.14132508864693816, 0.07066254432346908, 0.07066254432346908, 0.4484708399411081, 0.22423541997055405, 0.2001170225293779, 0.2001170225293779, 0.2001170225293779, 0.2001170225293779, 0.3415006474053264, 0.2169476052585481, 0.2169476052585481, 0.2169476052585481, 0.2169476052585481, 0.2169476052585481, 0.25083679876556886, 0.2500149417830819, 0.2500149417830819, 0.4250143236337771, 0.14167144121125905, 0.14167144121125905, 0.14167144121125905, 0.14167144121125905, 0.47467351265321767, 0.23733675632660883, 0.23733675632660883, 0.15853867734183028, 0.19024641281019633, 0.15853867734183028, 0.19024641281019633, 0.031707735468366055, 0.15853867734183028, 0.06341547093673211, 0.031707735468366055, 0.031707735468366055, 0.19534328979071697, 0.39068657958143393, 0.24310758495221865, 0.24310758495221865, 0.24310758495221865, 0.20326634709415142, 0.20326634709415142, 0.6097990412824542, 0.8386618700638142, 0.24329452981194077, 0.24329452981194077, 0.24329452981194077, 0.17312288232451886, 0.21640360290564858, 0.043280720581129715, 0.08656144116225943, 0.12984216174338914, 0.08656144116225943, 0.08656144116225943, 0.043280720581129715, 0.08656144116225943, 0.2029056549595671, 0.4058113099191342, 0.2594170790788754, 0.5188341581577508, 0.26672439205133724, 0.5334487841026745, 0.4670375945242249, 0.23351879726211244, 0.8405903226860533, 0.20414613839232695, 0.20414613839232695, 0.6124384151769808, 0.1981073385939825, 0.5943220157819474, 0.26815757034055043, 0.5363151406811009, 0.07428701277488363, 0.14857402554976726, 0.2971480510995345, 0.07428701277488363, 0.14857402554976726, 0.07428701277488363, 0.07428701277488363, 0.19371750222731765, 0.3874350044546353, 0.3248370011108414, 0.4578320484799193, 0.22891602423995966, 0.2948058383960638, 0.10528779942716564, 0.06317267965629939, 0.16846047908346504, 0.12634535931259877, 0.06317267965629939, 0.08423023954173252, 0.06317267965629939, 0.04211511977086626, 0.6169268418022001, 0.23134756567582504, 0.15423171045055004, 0.32169673368043317, 0.20354692014597436, 0.20354692014597436, 0.20354692014597436, 0.610640760437923, 0.30480841027102634, 0.21449480722775927, 0.10160280342367543, 0.10160280342367543, 0.0677352022824503, 0.07902440266285868, 0.0677352022824503, 0.04515680152163353, 0.03386760114122515, 0.08658438646161436, 0.12987657969242156, 0.17316877292322871, 0.12987657969242156, 0.08658438646161436, 0.12987657969242156, 0.08658438646161436, 0.17316877292322871, 0.04329219323080718, 0.19259272952591475, 0.14444454714443605, 0.2888890942888721, 0.09629636476295737, 0.04814818238147869, 0.09629636476295737, 0.09629636476295737, 0.04814818238147869, 0.23235107504602567, 0.1394106450276154, 0.09294043001841026, 0.1394106450276154, 0.1394106450276154, 0.04647021500920513, 0.09294043001841026, 0.1394106450276154, 0.04647021500920513, 0.3430536357727348, 0.1960421295583856, 0.3920842591167712, 0.3920842591167712, 0.2061221648611279, 0.2061221648611279, 0.6183664945833837, 0.20192775513947914, 0.20192775513947914, 0.20192775513947914, 0.20192775513947914, 0.17675078891523802, 0.17675078891523802, 0.5302523667457141, 0.17342989998786043, 0.34685979997572086, 0.34685979997572086, 0.17342989998786043, 0.11441369746081764, 0.11441369746081764, 0.11441369746081764, 0.22882739492163529, 0.22882739492163529, 0.11441369746081764, 0.2661945271236678, 0.5323890542473356, 0.053618135249508043, 0.16085440574852414, 0.3753269467465563, 0.053618135249508043, 0.10723627049901609, 0.10723627049901609, 0.053618135249508043, 0.053618135249508043, 0.053618135249508043, 0.3604757769016218, 0.1602114564007208, 0.1201585923005406, 0.0801057282003604, 0.0400528641001802, 0.0801057282003604, 0.0400528641001802, 0.0400528641001802, 0.25781085223947936, 0.25781085223947936, 0.1810483482882854, 0.26151428086085665, 0.08046593257257129, 0.12069889885885693, 0.08046593257257129, 0.12069889885885693, 0.04023296628628564, 0.060349449429428464, 0.02011648314314282, 0.24968938295524298, 0.18726703721643226, 0.062422345738810746, 0.12484469147762149, 0.12484469147762149, 0.062422345738810746, 0.18726703721643226, 0.062422345738810746, 0.19361861187706828, 0.38723722375413655, 0.25741122493709434, 0.12870561246854717, 0.06435280623427359, 0.1501565478799717, 0.1501565478799717, 0.06435280623427359, 0.06435280623427359, 0.08580374164569812, 0.02145093541142453, 0.38323341596043065, 0.12774447198681022, 0.04258149066227007, 0.04258149066227007, 0.08516298132454014, 0.04258149066227007, 0.08516298132454014, 0.2129074533113504, 0.15278868956330183, 0.15278868956330183, 0.15278868956330183, 0.15278868956330183, 0.15278868956330183, 0.15278868956330183, 0.465639802146054, 0.232819901073027, 0.232819901073027, 0.46881681221122945, 0.23440840610561473, 0.26324357368235324, 0.13162178684117662, 0.13162178684117662, 0.14415719511176486, 0.06894474548823537, 0.08774785789411774, 0.1065509703000001, 0.037606224811764746, 0.025070816541176495, 0.311758852321576, 0.623517704643152, 0.19140489005683223, 0.19140489005683223, 0.19140489005683223, 0.11484293403409934, 0.11484293403409934, 0.07656195602273289, 0.07656195602273289, 0.03828097801136644, 0.03828097801136644, 0.18273146197819312, 0.18273146197819312, 0.09136573098909656, 0.36546292395638624, 0.18273146197819312, 0.42286371545164014, 0.14095457181721338, 0.14095457181721338, 0.14095457181721338, 0.14095457181721338, 0.14095457181721338, 0.6256341972868371, 0.10427236621447286, 0.10427236621447286, 0.10427236621447286, 0.6900836929332693, 0.17252092323331733, 0.8382768562578751, 0.8339656319188009, 0.09819136150910301, 0.09819136150910301, 0.4909568075455151, 0.09819136150910301, 0.09819136150910301, 0.09819136150910301, 0.2526030836996716, 0.2526030836996716, 0.2526030836996716, 0.19564205452082314, 0.19564205452082314, 0.06521401817360772, 0.13042803634721545, 0.06521401817360772, 0.06521401817360772, 0.19564205452082314, 0.06521401817360772, 0.3418878927635195, 0.6879560893898273, 0.17198902234745683, 0.10518750245985292, 0.31556250737955877, 0.10518750245985292, 0.10518750245985292, 0.10518750245985292, 0.21037500491970584, 0.10518750245985292, 0.10518750245985292, 0.2431711770327757, 0.2431711770327757, 0.10734072634463773, 0.10734072634463773, 0.21468145268927546, 0.21468145268927546, 0.21468145268927546, 0.19417283110950267, 0.38834566221900535, 0.13646090043929937, 0.13646090043929937, 0.13646090043929937, 0.13646090043929937, 0.40938270131789817, 0.19188766823759515, 0.19188766823759515, 0.15351013459007612, 0.09594383411879757, 0.07675506729503806, 0.07675506729503806, 0.09594383411879757, 0.07675506729503806, 0.03837753364751903, 0.48598416056916544, 0.24299208028458272, 0.1948257936116491, 0.3896515872232982, 0.09741289680582454, 0.09741289680582454, 0.09741289680582454, 0.09741289680582454, 0.25245393219046164, 0.25245393219046164, 0.25245393219046164, 0.13758396834897005, 0.06879198417448502, 0.20637595252345506, 0.20637595252345506, 0.2751679366979401, 0.06879198417448502, 0.3284675665524249, 0.3368113500463463, 0.22494266777230082, 0.19682483430076322, 0.16870700082922563, 0.08435350041461281, 0.056235666943075205, 0.056235666943075205, 0.16870700082922563, 0.056235666943075205, 0.028117833471537602, 0.41817606774989863, 0.11004633361839437, 0.0880370668947155, 0.1210509669802338, 0.06602780017103663, 0.04401853344735775, 0.07703243353287606, 0.06602780017103663, 0.022009266723678873, 0.25373022988108546, 0.25373022988108546, 0.25373022988108546, 0.251874901818777, 0.251874901818777, 0.251874901818777, 0.1608432992961647, 0.1608432992961647, 0.4825298978884941, 0.2879969746313503, 0.2039978570305398, 0.11999873942972929, 0.10799886548675637, 0.03599962182891879, 0.10799886548675637, 0.04799949577189172, 0.02399974788594586, 0.04799949577189172, 0.2503409735644364, 0.2503409735644364, 0.1506937659880521, 0.1506937659880521, 0.3767344149701302, 0.07534688299402605, 0.07534688299402605, 0.07534688299402605, 0.07534688299402605, 0.07534688299402605, 0.3386420140880397, 0.11288067136267989, 0.11288067136267989, 0.22576134272535978, 0.11288067136267989, 0.25346247482983525, 0.25346247482983525, 0.6905274293551226, 0.17263185733878064, 0.07750831503970004, 0.1550166300794001, 0.46504989023820026, 0.07750831503970004, 0.07750831503970004, 0.07750831503970004, 0.07750831503970004, 0.1517878553233668, 0.0758939276616834, 0.0758939276616834, 0.0758939276616834, 0.1517878553233668, 0.0758939276616834, 0.0758939276616834, 0.3035757106467336, 0.20644252046693692, 0.20644252046693692, 0.6193275614008107, 0.30063390251641725, 0.30063390251641725, 0.11333756387600291, 0.11333756387600291, 0.11333756387600291, 0.22667512775200582, 0.11333756387600291, 0.34001269162800873, 0.685918247948992, 0.171479561987248, 0.3114121252733094, 0.18684727516398567, 0.06228242505466189, 0.06228242505466189, 0.06228242505466189, 0.12456485010932378, 0.06228242505466189, 0.06228242505466189, 0.06228242505466189, 0.1883156907332307, 0.5649470721996921, 0.16598759609846744, 0.24898139414770118, 0.08299379804923372, 0.08299379804923372, 0.24898139414770118, 0.08299379804923372, 0.09568586428057668, 0.12758115237410222, 0.2232670166546789, 0.19137172856115336, 0.09568586428057668, 0.06379057618705111, 0.06379057618705111, 0.12758115237410222, 0.031895288093525556, 0.3367475527039549, 0.23390259551831608, 0.11695129775915804, 0.23390259551831608, 0.23390259551831608, 0.11695129775915804, 0.47958593182366394, 0.23979296591183197, 0.6777241123953951, 0.16943102809884877, 0.24236156224309227, 0.17311540160220876, 0.06924616064088351, 0.10386924096132526, 0.06924616064088351, 0.17311540160220876, 0.06924616064088351, 0.06924616064088351, 0.03462308032044176, 0.3298694799516502, 0.6874964536962476, 0.1718741134240619, 0.3514357456461564, 0.6813586651852043, 0.17033966629630107, 0.4676171744978748, 0.2338085872489374, 0.2338085872489374, 0.19074531979506204, 0.21458848476944478, 0.16690215482067927, 0.09537265989753102, 0.09537265989753102, 0.11921582487191376, 0.09537265989753102, 0.023843164974382755, 0.023843164974382755, 0.46260939333106343, 0.23130469666553172, 0.3005306264324379, 0.3005306264324379, 0.4713167143609821, 0.23565835718049105, 0.16357630243726384, 0.16357630243726384, 0.49072890731179153, 0.6873069219555605, 0.17182673048889013, 0.24449435564287167, 0.24449435564287167, 0.24449435564287167, 0.1752089535664979, 0.08760447678324895, 0.08760447678324895, 0.08760447678324895, 0.1752089535664979, 0.08760447678324895, 0.08760447678324895, 0.08760447678324895, 0.08760447678324895, 0.2516527738409547, 0.2516527738409547, 0.2516527738409547, 0.6873001215195442, 0.17182503037988606, 0.3061481252595369, 0.6122962505190738, 0.26098795177761147, 0.5219759035552229, 0.12017147944335273, 0.24034295888670545, 0.12017147944335273, 0.12017147944335273, 0.3605144383300582, 0.12017147944335273, 0.2909141494956199, 0.2909141494956199, 0.04848569158260332, 0.04848569158260332, 0.04848569158260332, 0.09697138316520663, 0.04848569158260332, 0.04848569158260332, 0.04848569158260332, 0.23796767596016907, 0.23796767596016907, 0.23796767596016907, 0.4752107078783884, 0.2376053539391942, 0.2315347198781101, 0.11576735993905506, 0.2315347198781101, 0.11576735993905506, 0.2315347198781101, 0.11842830045756798, 0.17764245068635198, 0.17764245068635198, 0.11842830045756798, 0.05921415022878399, 0.05921415022878399, 0.23685660091513597, 0.3088483561607879, 0.6176967123215757, 0.2729774765968895, 0.22334520812472777, 0.09926453694432345, 0.12408067118040432, 0.04963226847216173, 0.12408067118040432, 0.04963226847216173, 0.024816134236080863, 0.024816134236080863, 0.06689675296617581, 0.26758701186470324, 0.20069025889852743, 0.06689675296617581, 0.06689675296617581, 0.06689675296617581, 0.06689675296617581, 0.06689675296617581, 0.3323443199900626, 0.07678949125116187, 0.15357898250232374, 0.3839474562558094, 0.07678949125116187, 0.15357898250232374, 0.07678949125116187, 0.07678949125116187, 0.07678949125116187, 0.17305432111296465, 0.13233565732167885, 0.13233565732167885, 0.15269498921732175, 0.07125766163475014, 0.1221559913738574, 0.05089832973910725, 0.13233565732167885, 0.03053899784346435, 0.29949161580521616, 0.18718225987826012, 0.07487290395130404, 0.11230935592695607, 0.11230935592695607, 0.03743645197565202, 0.11230935592695607, 0.03743645197565202, 0.03743645197565202, 0.19544947717308264, 0.13029965144872177, 0.21173693360417287, 0.11401219501763155, 0.13029965144872177, 0.06514982572436089, 0.03257491286218044, 0.09772473858654132, 0.01628745643109022, 0.28554148492857456, 0.16316656281632833, 0.12237492211224625, 0.04079164070408208, 0.12237492211224625, 0.04079164070408208, 0.04079164070408208, 0.12237492211224625, 0.04079164070408208, 0.25661329408523254, 0.25661329408523254, 0.2880767090567551, 0.2880767090567551, 0.05761534181135102, 0.05761534181135102, 0.05761534181135102, 0.17284602543405306, 0.05761534181135102, 0.2005351819586018, 0.2005351819586018, 0.2005351819586018, 0.2005351819586018, 0.3343194444999007, 0.25153335409610433, 0.1572083463100652, 0.12576667704805217, 0.09432500778603911, 0.09432500778603911, 0.06288333852402608, 0.09432500778603911, 0.06288333852402608, 0.06288333852402608, 0.2630473594181, 0.2630473594181, 0.19243620494109376, 0.19243620494109376, 0.3848724098821875, 0.13428614839785472, 0.13428614839785472, 0.08952409893190315, 0.13428614839785472, 0.08952409893190315, 0.08952409893190315, 0.22381024732975785, 0.08952409893190315, 0.044762049465951574, 0.3905144272303087, 0.09762860680757718, 0.09762860680757718, 0.29288582042273154, 0.24350876085437484, 0.24350876085437484, 0.17862292583308026, 0.21434751099969632, 0.1428983406664642, 0.0714491703332321, 0.10717375549984816, 0.10717375549984816, 0.0714491703332321, 0.0714491703332321, 0.03572458516661605, 0.25190293275889825, 0.25190293275889825, 0.3285595811563326, 0.3285595811563326, 0.10951986038544419, 0.2027936075213055, 0.2027936075213055, 0.6083808225639166, 0.239807652377535, 0.239807652377535, 0.239807652377535, 0.2381651124409144, 0.2381651124409144, 0.1190825562204572, 0.2381651124409144, 0.19853684648014433, 0.19853684648014433, 0.19853684648014433, 0.19853684648014433, 0.20798088881520038, 0.20798088881520038, 0.6239426664456011, 0.24128772660145925, 0.24128772660145925, 0.24128772660145925, 0.20069665608339687, 0.20069665608339687, 0.6020899682501906, 0.46461695072484027, 0.23230847536242014, 0.30461385824452863, 0.6092277164890573, 0.2631462220304417, 0.5262924440608834, 0.31289466832185625, 0.6257893366437125, 0.2746281901393337, 0.201767649898286, 0.06165122635780961, 0.1737443651901907, 0.07846519718266677, 0.08406985412428583, 0.039232598591333386, 0.06725588329942866, 0.022418627766476223, 0.3129348412047337, 0.6258696824094674, 0.13180872004869454, 0.17574496006492607, 0.13180872004869454, 0.13180872004869454, 0.04393624001623152, 0.21968120008115757, 0.04393624001623152, 0.04393624001623152, 0.04393624001623152, 0.2555332719270308, 0.2555332719270308, 0.2555332719270308, 0.11295500333425083, 0.22591000666850167, 0.22591000666850167, 0.11295500333425083, 0.22591000666850167, 0.1548569106337501, 0.1548569106337501, 0.18066639573937512, 0.1548569106337501, 0.07742845531687505, 0.10323794042250006, 0.05161897021125003, 0.07742845531687505, 0.025809485105625016, 0.2558691228386471, 0.2558691228386471, 0.1905819483797879, 0.5717458451393637, 0.6883081473629189, 0.17207703684072972, 0.25293718960999817, 0.6828437692426825, 0.17071094231067063, 0.47867068559462567, 0.23933534279731283, 0.06324819743177648, 0.12649639486355296, 0.31624098715888244, 0.12649639486355296, 0.06324819743177648, 0.2529927897271059, 0.06324819743177648, 0.300569416995554, 0.16394695472484763, 0.13662246227070635, 0.10929796981656509, 0.08197347736242382, 0.08197347736242382, 0.08197347736242382, 0.054648984908282544, 0.027324492454141272, 0.3167233945310402, 0.3405727637955276, 0.1702863818977638, 0.1702863818977638, 0.4681342102303682, 0.2340671051151841, 0.2340671051151841, 0.20664790047904033, 0.15498592535928024, 0.2583098755988004, 0.10332395023952017, 0.10332395023952017, 0.05166197511976008, 0.05166197511976008, 0.05166197511976008, 0.05166197511976008, 0.19185419940400616, 0.20929549025891583, 0.10464774512945792, 0.15697161769418688, 0.12208903598436757, 0.061044517992183786, 0.0697651634196386, 0.05232387256472896, 0.02616193628236448, 0.10280489347438938, 0.10280489347438938, 0.5140244673719468, 0.10280489347438938, 0.1877665510645934, 0.12517770070972892, 0.12517770070972892, 0.06258885035486446, 0.06258885035486446, 0.06258885035486446, 0.1877665510645934, 0.06258885035486446, 0.06258885035486446, 0.6914776686377619, 0.17286941715944049, 0.20643873297282117, 0.41287746594564234, 0.24172884687073337, 0.24172884687073337, 0.24172884687073337, 0.12545805491951825, 0.12545805491951825, 0.37637416475855473, 0.2509161098390365, 0.2661221050024739, 0.5322442100049478, 0.8357481137132887, 0.2654556182196261, 0.5309112364392522, 0.19755774632313292, 0.39511549264626583, 0.19755774632313292, 0.18659072511496452, 0.18659072511496452, 0.18659072511496452, 0.37318145022992905, 0.18659072511496452, 0.14843272411395386, 0.24738787352325642, 0.2968654482279077, 0.049477574704651285, 0.049477574704651285, 0.049477574704651285, 0.049477574704651285, 0.049477574704651285, 0.049477574704651285, 0.2459777612941995, 0.1998569310515371, 0.10761527056621228, 0.16910971088976215, 0.046120830242662406, 0.12298888064709974, 0.030747220161774936, 0.046120830242662406, 0.030747220161774936, 0.2356389878185296, 0.1178194939092648, 0.1178194939092648, 0.1178194939092648, 0.2356389878185296, 0.22428886172875734, 0.1922475957675063, 0.09612379788375315, 0.1281650638450042, 0.1281650638450042, 0.1281650638450042, 0.03204126596125105, 0.0640825319225021, 0.03204126596125105, 0.2849650486852552, 0.2849650486852552, 0.16613454730785873, 0.22151272974381161, 0.12921575901722346, 0.12921575901722346, 0.11075636487190581, 0.09229697072658818, 0.036918788290635274, 0.055378182435952904, 0.036918788290635274, 0.3079279944212975, 0.123171197768519, 0.09237839832638925, 0.123171197768519, 0.09237839832638925, 0.0615855988842595, 0.0615855988842595, 0.0615855988842595, 0.03079279944212975, 0.23862149405227415, 0.11931074702613707, 0.23862149405227415, 0.23862149405227415, 0.207062328092574, 0.207062328092574, 0.207062328092574, 0.207062328092574, 0.20239101968284412, 0.20239101968284412, 0.6071730590485324, 0.20711566659237893, 0.20711566659237893, 0.41423133318475786, 0.061009949242741356, 0.18302984772822406, 0.42706964469918945, 0.061009949242741356, 0.061009949242741356, 0.061009949242741356, 0.061009949242741356, 0.061009949242741356, 0.061009949242741356, 0.1933688351405928, 0.3867376702811856, 0.3867376702811856, 0.19670659365690749, 0.39341318731381497, 0.19670659365690749, 0.3266247953149697, 0.4650369198426516, 0.2325184599213258, 0.34374935311808397, 0.2071866386364691, 0.4143732772729382, 0.09114069219059488, 0.36456276876237953, 0.09114069219059488, 0.09114069219059488, 0.09114069219059488, 0.18228138438118976, 0.4580229033856135, 0.22901145169280676, 0.46610896743643115, 0.23305448371821558, 0.19938289073631515, 0.19938289073631515, 0.5981486722089455, 0.30385326462008105, 0.21703804615720076, 0.0868152184628803, 0.0868152184628803, 0.0868152184628803, 0.13022282769432045, 0.0868152184628803, 0.04340760923144015, 0.04340760923144015, 0.21530299629430033, 0.21530299629430033, 0.21530299629430033, 0.21530299629430033, 0.21226771176834416, 0.21226771176834416, 0.21226771176834416, 0.21226771176834416, 0.3355715807289435, 0.25236422267618075, 0.2078293598509724, 0.13360458847562512, 0.163294497025764, 0.04453486282520837, 0.08906972565041674, 0.05937981710027783, 0.029689908550138915, 0.014844954275069457, 0.2575506223366368, 0.2575506223366368, 0.5618257550277242, 0.07022821937846553, 0.14045643875693106, 0.07022821937846553, 0.07022821937846553, 0.07022821937846553, 0.07022821937846553, 0.07022821937846553, 0.15899220581699705, 0.15899220581699705, 0.15899220581699705, 0.07949610290849853, 0.1192441543627478, 0.1192441543627478, 0.0596220771813739, 0.09937012863562315, 0.03974805145424926, 0.2602228881151633, 0.2602228881151633, 0.6897704255578015, 0.1724426063894504, 0.6876052278401893, 0.17190130696004732, 0.16588607818220996, 0.08294303909110498, 0.08294303909110498, 0.24882911727331494, 0.16588607818220996, 0.08294303909110498, 0.08294303909110498, 0.20539782617679794, 0.20539782617679794, 0.4107956523535959, 0.24986126552212923, 0.24986126552212923, 0.1942596906329628, 0.3885193812659256, 0.3885193812659256, 0.4680306224328475, 0.23401531121642374, 0.23401531121642374, 0.27428786680812267, 0.13714393340406134, 0.41143180021218406, 0.3263730262599494, 0.17494477008365603, 0.131208577562742, 0.08747238504182801, 0.14578730840304668, 0.131208577562742, 0.131208577562742, 0.10205111588213267, 0.05831492336121867, 0.043736192520914006, 0.21116774240731984, 0.21116774240731984, 0.21116774240731984, 0.21116774240731984, 0.20013581868152072, 0.20013581868152072, 0.20013581868152072, 0.40027163736304144, 0.23275810362974253, 0.16114022558982175, 0.16114022558982175, 0.10742681705988116, 0.07161787803992077, 0.08952234754990097, 0.10742681705988116, 0.035808939019960385, 0.035808939019960385, 0.33115825383444336, 0.12042118321252486, 0.24084236642504972, 0.06021059160626243, 0.06021059160626243, 0.06021059160626243, 0.06021059160626243, 0.030105295803131215, 0.030105295803131215, 0.26780232585629876, 0.5356046517125975, 0.3103578010512578, 0.1379368004672257, 0.10345260035041928, 0.10345260035041928, 0.1379368004672257, 0.034484200116806425, 0.034484200116806425, 0.10345260035041928, 0.034484200116806425, 0.1929691638560315, 0.1929691638560315, 0.385938327712063, 0.22407079388105233, 0.1493805292540349, 0.1493805292540349, 0.11203539694052617, 0.07469026462701744, 0.11203539694052617, 0.07469026462701744, 0.07469026462701744, 0.03734513231350872, 0.20591639250885296, 0.20591639250885296, 0.17159699375737747, 0.034319398751475494, 0.06863879750295099, 0.06863879750295099, 0.13727759500590198, 0.034319398751475494, 0.034319398751475494, 0.09421613440070885, 0.14132420160106327, 0.14132420160106327, 0.14132420160106327, 0.14132420160106327, 0.09421613440070885, 0.047108067200354424, 0.14132420160106327, 0.331022702251452, 0.20825074394960622, 0.41650148789921243, 0.12089520857268259, 0.12089520857268259, 0.12089520857268259, 0.36268562571804774, 0.12089520857268259, 0.16756693266304226, 0.23040453241168313, 0.18851279924592257, 0.08378346633152113, 0.10472933291440142, 0.08378346633152113, 0.08378346633152113, 0.041891733165760565, 0.041891733165760565, 0.10647948651760841, 0.21295897303521683, 0.5323974325880421, 0.10647948651760841, 0.22650526198615692, 0.16178947284725492, 0.19414736741670593, 0.09707368370835297, 0.06471578913890197, 0.12943157827780394, 0.06471578913890197, 0.032357894569450985, 0.032357894569450985, 0.14951577609738265, 0.14951577609738265, 0.2990315521947653, 0.14951577609738265, 0.14951577609738265, 0.18986662600917445, 0.3797332520183489, 0.3797332520183489, 0.1003620466369397, 0.1003620466369397, 0.2007240932738794, 0.2007240932738794, 0.1003620466369397, 0.3010861399108191, 0.33821169476131213, 0.19414254348262047, 0.19414254348262047, 0.19414254348262047, 0.38828508696524094, 0.19414254348262047, 0.2673169969455738, 0.5346339938911476, 0.11159712839688561, 0.11159712839688561, 0.11159712839688561, 0.22319425679377122, 0.3347913851906568, 0.26528811243863565, 0.5305762248772713, 0.15566049399647366, 0.15566049399647366, 0.2334907409947105, 0.07783024699823683, 0.07783024699823683, 0.15566049399647366, 0.07783024699823683, 0.4682907781529714, 0.2341453890764857, 0.40068349839758566, 0.13356116613252855, 0.2671223322650571, 0.20313399217687494, 0.16250719374149997, 0.12188039530612498, 0.08125359687074998, 0.08125359687074998, 0.08125359687074998, 0.20313399217687494, 0.04062679843537499, 0.04062679843537499, 0.33134027217811, 0.20472915846826037, 0.20472915846826037, 0.6141874754047811, 0.21653762014523772, 0.21653762014523772, 0.21653762014523772, 0.21653762014523772, 0.19263285286659954, 0.38526570573319907, 0.38526570573319907, 0.21333533314023673, 0.21333533314023673, 0.21333533314023673, 0.21333533314023673, 0.26310069538988323, 0.5262013907797665, 0.20599050075424324, 0.4119810015084865, 0.4662209260372538, 0.2331104630186269, 0.4546095502932838, 0.2273047751466419, 0.045460955029328384, 0.06819143254399257, 0.06819143254399257, 0.022730477514664192, 0.022730477514664192, 0.045460955029328384, 0.045460955029328384, 0.18695991584991875, 0.12463994389994584, 0.4362398036498104, 0.06231997194997292, 0.06231997194997292, 0.06231997194997292, 0.06231997194997292, 0.47299006238937624, 0.23649503119468812, 0.20411134716100568, 0.40822269432201136, 0.2303676821643045, 0.17917486390557016, 0.153578454776203, 0.0767892273881015, 0.0767892273881015, 0.051192818258734334, 0.051192818258734334, 0.153578454776203, 0.025596409129367167, 0.32707534362959134, 0.20241191860358285, 0.20241191860358285, 0.20241191860358285, 0.20241191860358285, 0.20478157469407096, 0.20478157469407096, 0.20478157469407096, 0.20478157469407096, 0.5360514201045857, 0.1531575486013102, 0.0765787743006551, 0.0765787743006551, 0.0765787743006551, 0.0765787743006551, 0.0765787743006551, 0.6901161425366402, 0.17252903563416006, 0.19334560750017957, 0.19334560750017957, 0.38669121500035913, 0.46899041610546527, 0.23449520805273263, 0.33357703579196607, 0.32788279588004676, 0.1654274982675796, 0.0827137491337898, 0.0827137491337898, 0.3308549965351592, 0.0827137491337898, 0.1654274982675796, 0.33358718507491314, 0.30526793375792166, 0.6105358675158433, 0.40564636064211257, 0.20282318032105628, 0.05070579508026407, 0.05070579508026407, 0.05070579508026407, 0.05070579508026407, 0.05070579508026407, 0.1784024199963243, 0.14272193599705946, 0.24976338799485404, 0.10704145199779459, 0.07136096799852973, 0.07136096799852973, 0.07136096799852973, 0.035680483999264864, 0.035680483999264864, 0.3087181453317859, 0.14623491094663543, 0.16248323438515047, 0.08124161719257524, 0.04874497031554514, 0.09748994063109027, 0.06499329375406018, 0.06499329375406018, 0.016248323438515046, 0.12469031024605047, 0.062345155123025235, 0.18703546536907573, 0.3117257756151262, 0.12469031024605047, 0.062345155123025235, 0.062345155123025235, 0.062345155123025235, 0.20288498515761436, 0.20288498515761436, 0.20288498515761436, 0.20288498515761436, 0.19225762371850463, 0.19225762371850463, 0.38451524743700927, 0.24044783654819232, 0.24044783654819232, 0.24044783654819232, 0.24719491047611258, 0.1441970311110657, 0.12359745523805629, 0.10299787936504691, 0.08239830349203753, 0.08239830349203753, 0.10299787936504691, 0.08239830349203753, 0.020599575873009382, 0.19738105354862473, 0.39476210709724946, 0.19415856371234516, 0.09707928185617258, 0.19415856371234516, 0.09707928185617258, 0.04853964092808629, 0.19415856371234516, 0.09707928185617258, 0.04853964092808629, 0.46774562627589694, 0.23387281313794847, 0.19454654905326998, 0.38909309810653997, 0.38909309810653997, 0.16177642773236356, 0.16177642773236356, 0.2696273795539393, 0.16177642773236356, 0.053925475910787855, 0.053925475910787855, 0.10785095182157571, 0.053925475910787855, 0.19958757833337654, 0.19958757833337654, 0.19958757833337654, 0.19958757833337654, 0.25414136718310826, 0.25414136718310826, 0.46852974898753647, 0.23426487449376823, 0.23426487449376823, 0.5601359791120666, 0.21005099216702494, 0.07001699738900832, 0.07001699738900832, 0.07001699738900832, 0.6877545624854433, 0.17193864062136083, 0.11008784403004278, 0.11008784403004278, 0.11008784403004278, 0.11008784403004278, 0.14678379204005704, 0.07339189602002852, 0.03669594801001426, 0.22017568806008556, 0.03669594801001426, 0.42240474954650264, 0.10560118738662566, 0.10560118738662566, 0.10560118738662566, 0.10560118738662566, 0.10560118738662566, 0.20260649102688752, 0.20260649102688752, 0.40521298205377504, 0.5812040380499286, 0.11624080760998572, 0.11624080760998572, 0.11624080760998572, 0.690640308794468, 0.172660077198617, 0.1775293716563513, 0.11835291443756754, 0.05917645721878377, 0.11835291443756754, 0.11835291443756754, 0.11835291443756754, 0.11835291443756754, 0.1775293716563513, 0.46495908804005753, 0.23247954402002877, 0.32993345332879265, 0.1930380567136253, 0.3860761134272506, 0.20780984712784645, 0.6234295413835393, 0.6914075814115922, 0.17285189535289805, 0.4603854879467061, 0.20461577242075826, 0.051153943105189566, 0.10230788621037913, 0.051153943105189566, 0.051153943105189566, 0.051153943105189566, 0.051153943105189566, 0.051153943105189566, 0.28581923395099484, 0.14290961697549742, 0.14290961697549742, 0.14290961697549742, 0.14290961697549742, 0.4786357336287383, 0.23931786681436915, 0.24338527759078904, 0.24338527759078904, 0.06339536454386013, 0.1901860936315804, 0.25358145817544053, 0.12679072908772027, 0.1901860936315804, 0.06339536454386013, 0.06339536454386013, 0.15066709655939003, 0.15066709655939003, 0.2511118275989834, 0.050222365519796676, 0.10044473103959335, 0.10044473103959335, 0.10044473103959335, 0.050222365519796676, 0.050222365519796676, 0.6871733452676363, 0.17179333631690907, 0.6873375377629626, 0.17183438444074065, 0.11220228223513204, 0.11220228223513204, 0.3927079878229621, 0.11220228223513204, 0.11220228223513204, 0.05610114111756602, 0.05610114111756602, 0.08963323974025252, 0.08963323974025252, 0.35853295896101006, 0.17926647948050503, 0.08963323974025252, 0.08963323974025252, 0.26889971922075756, 0.21725950170881347, 0.21725950170881347, 0.21725950170881347, 0.21725950170881347, 0.2513475721464064, 0.2513475721464064, 0.24551425099527985, 0.24551425099527985, 0.24551425099527985, 0.19973009132798702, 0.39946018265597405, 0.1715508236551412, 0.1715508236551412, 0.0857754118275706, 0.0857754118275706, 0.1715508236551412, 0.0857754118275706, 0.0857754118275706, 0.0857754118275706, 0.1231529797739699, 0.06157648988698495, 0.18472946966095485, 0.3694589393219097, 0.06157648988698495, 0.06157648988698495, 0.10513693953354544, 0.21027387906709089, 0.10513693953354544, 0.10513693953354544, 0.21027387906709089, 0.10513693953354544, 0.10513693953354544, 0.10513693953354544, 0.19132510349047788, 0.19132510349047788, 0.38265020698095575, 0.18082532723042752, 0.15499313762608075, 0.20665751683477432, 0.12916094802173395, 0.10332875841738716, 0.05166437920869358, 0.07749656881304037, 0.05166437920869358, 0.02583218960434679, 0.20856632320782548, 0.20856632320782548, 0.20856632320782548, 0.20856632320782548, 0.2635472922268124, 0.2635472922268124, 0.07529922635051783, 0.07529922635051783, 0.07529922635051783, 0.11294883952577675, 0.03764961317525892, 0.03764961317525892, 0.03764961317525892, 0.33394957351820925, 0.20959062297825534, 0.628771868934766, 0.12074126401535323, 0.12074126401535323, 0.4225944240537363, 0.06037063200767662, 0.12074126401535323, 0.06037063200767662, 0.06037063200767662, 0.06037063200767662, 0.11683603088023466, 0.15578137450697954, 0.19472671813372444, 0.2726174053872142, 0.11683603088023466, 0.07789068725348977, 0.038945343626744885, 0.038945343626744885, 0.29839908881985244, 0.29839908881985244, 0.16545228737528764, 0.16545228737528764, 0.4963568621258629, 0.3180883588447236, 0.24740205687922945, 0.10602945294824119, 0.10602945294824119, 0.03534315098274706, 0.07068630196549412, 0.03534315098274706, 0.03534315098274706, 0.03534315098274706], \"Term\": [\"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"absolutely\", \"ace\", \"ace\", \"achievement\", \"actingthe\", \"actingthe\", \"actingthe\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"actionpacked\", \"actionpacked\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"adventure\", \"adventure\", \"affectively\", \"affectively\", \"againdirection\", \"aided\", \"aided\", \"alone\", \"alone\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"always\", \"always\", \"always\", \"always\", \"always\", \"always\", \"always\", \"always\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazingthis\", \"amazingthis\", \"american\", \"american\", \"american\", \"american\", \"american\", \"andy\", \"andy\", \"andy\", \"andy\", \"andy\", \"andy\", \"andy\", \"andy\", \"andy\", \"angry\", \"angry\", \"angry\", \"angry\", \"antihero\", \"antihero\", \"antihero\", \"arresting\", \"arresting\", \"asskicking\", \"asskicking\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"audience\", \"audience\", \"audience\", \"audience\", \"audience\", \"audience\", \"avengers\", \"avengers\", \"awesomeat\", \"awesomeat\", \"badboys\", \"barely\", \"barely\", \"barely\", \"barely\", \"barely\", \"barely\", \"barely\", \"batcharisma\", \"batcharisma\", \"batcharisma\", \"batman\", \"batman\", \"batman\", \"batman\", \"batman\", \"batman\", \"batman\", \"batman\", \"batman\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"batmans\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"becoming\", \"becoming\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"biden\", \"biden\", \"biden\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blatantly\", \"blatantly\", \"bob\", \"bob\", \"bombast\", \"bombast\", \"bombastic\", \"bombastic\", \"boo\", \"boo\", \"boo\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"books\", \"books\", \"bore\", \"bore\", \"bore\", \"boring\", \"boring\", \"boring\", \"boring\", \"boring\", \"boring\", \"borrow\", \"borrow\", \"boys\", \"bringing\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"bruce\", \"budget\", \"budget\", \"buick\", \"buick\", \"built\", \"built\", \"built\", \"built\", \"burner\", \"burner\", \"caliber\", \"caliber\", \"caliber\", \"caped\", \"caped\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"cast\", \"casts\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"catch\", \"catch\", \"certainly\", \"certainly\", \"certainly\", \"certainly\", \"certainly\", \"certainly\", \"certainly\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"characters\", \"childhood\", \"chinlunds\", \"chinlunds\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"cinematographer\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"cinematography\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"close\", \"close\", \"close\", \"colin\", \"colin\", \"colin\", \"colin\", \"colin\", \"colin\", \"colin\", \"colin\", \"colin\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"comic\", \"commentary\", \"commentary\", \"commentary\", \"complete\", \"complete\", \"complete\", \"complex\", \"complex\", \"composition\", \"composition\", \"compositions\", \"condemnation\", \"connect\", \"connect\", \"connection\", \"connection\", \"connection\", \"connection\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"corrupt\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"couldnt\", \"couldnt\", \"couldnt\", \"couldnt\", \"couldnt\", \"couldnt\", \"couldnt\", \"couldnt\", \"credits\", \"credits\", \"credits\", \"creepy\", \"creepy\", \"creepy\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crimes\", \"cursader\", \"cursader\", \"cylinders\", \"cylinders\", \"damn\", \"damn\", \"damn\", \"dano\", \"dano\", \"dano\", \"dano\", \"dano\", \"dano\", \"dano\", \"dano\", \"dano\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"darker\", \"darker\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"de\", \"de\", \"dead\", \"dead\", \"dead\", \"dead\", \"deaths\", \"decent\", \"decent\", \"decent\", \"decent\", \"decent\", \"deserves\", \"deservesrobert\", \"deservesrobert\", \"design\", \"design\", \"design\", \"design\", \"design\", \"destroying\", \"destroying\", \"destroying\", \"detective\", \"detective\", \"detective\", \"detective\", \"detective\", \"detective\", \"detective\", \"detective\", \"detective\", \"device\", \"device\", \"dexter\", \"dexter\", \"dexter\", \"direction\", \"direction\", \"direction\", \"disappointment\", \"diversity\", \"diversity\", \"diversity\", \"done\", \"done\", \"done\", \"done\", \"done\", \"done\", \"done\", \"done\", \"done\", \"donning\", \"donning\", \"dramatic\", \"dramatic\", \"drawn\", \"drawn\", \"dread\", \"dread\", \"drivel\", \"editing\", \"editing\", \"editing\", \"editor\", \"editor\", \"effort\", \"effort\", \"emo\", \"emo\", \"emo\", \"emo\", \"emo\", \"emo\", \"emo\", \"emokid\", \"emokid\", \"employees\", \"employing\", \"employing\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enjoy\", \"enjoy\", \"enjoy\", \"ensemble\", \"escape\", \"escape\", \"escape\", \"escape\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everyone\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"everywhere\", \"evokes\", \"evokes\", \"evokes\", \"except\", \"except\", \"except\", \"exception\", \"exception\", \"exception\", \"exception\", \"expect\", \"expect\", \"expect\", \"explosive\", \"explosive\", \"explosive\", \"explosive\", \"extremely\", \"extremely\", \"extremely\", \"extremely\", \"extremely\", \"extremely\", \"faces\", \"faces\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"falcone\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fantasticpaul\", \"fantasticpaul\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"favourite\", \"favourite\", \"favourite\", \"favourite\", \"favourite\", \"favourite\", \"favourite\", \"favourite\", \"fear\", \"fear\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feels\", \"feels\", \"feels\", \"feels\", \"feels\", \"feels\", \"feels\", \"feels\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"fest\", \"fest\", \"fest\", \"field\", \"field\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"filmjust\", \"filmjust\", \"films\", \"films\", \"films\", \"films\", \"films\", \"films\", \"films\", \"films\", \"films\", \"final\", \"final\", \"final\", \"final\", \"final\", \"fing\", \"fing\", \"fing\", \"fing\", \"fing\", \"fing\", \"finish\", \"finish\", \"finish\", \"finish\", \"fires\", \"fires\", \"firstly\", \"fit\", \"focused\", \"focused\", \"focused\", \"focused\", \"focused\", \"focused\", \"fori\", \"fori\", \"fori\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"frailty\", \"franchise\", \"franchise\", \"fraser\", \"fraser\", \"fraser\", \"fraser\", \"fraser\", \"fraser\", \"fraser\", \"fraser\", \"free\", \"free\", \"gave\", \"gave\", \"gave\", \"gave\", \"gave\", \"general\", \"general\", \"generic\", \"generic\", \"generic\", \"generic\", \"generic\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"getting\", \"getting\", \"giacchino\", \"giacchino\", \"giacchino\", \"giacchino\", \"giacchino\", \"giacchino\", \"give\", \"give\", \"give\", \"gives\", \"gives\", \"gives\", \"gives\", \"gives\", \"gives\", \"godfather\", \"godfatherbatman\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"goosebumpsfight\", \"goosebumpsfight\", \"goosebumpsfight\", \"grandeur\", \"grandeur\", \"grandeur\", \"grayson\", \"grayson\", \"grayson\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greatcolin\", \"greatcolin\", \"greatest\", \"greatest\", \"greatest\", \"greatest\", \"greatest\", \"greatest\", \"greatest\", \"greatest\", \"greig\", \"greig\", \"greig\", \"greig\", \"greig\", \"grey\", \"grey\", \"grounded\", \"grounded\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"harley\", \"harley\", \"harley\", \"hasif\", \"hasif\", \"hated\", \"hated\", \"hated\", \"hated\", \"hated\", \"hated\", \"headline\", \"headline\", \"heath\", \"heath\", \"heath\", \"heath\", \"heath\", \"heath\", \"heath\", \"heath\", \"heath\", \"heavily\", \"heavily\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hero\", \"hes\", \"hes\", \"hes\", \"hes\", \"hes\", \"hes\", \"hes\", \"hes\", \"hes\", \"hiding\", \"high\", \"high\", \"high\", \"high\", \"high\", \"homicidal\", \"homicidal\", \"hoping\", \"hoping\", \"hours\", \"hours\", \"hours\", \"hours\", \"hours\", \"hours\", \"hours\", \"hours\", \"hours\", \"housed\", \"huge\", \"huge\", \"humor\", \"hype\", \"hype\", \"ill\", \"ill\", \"ill\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"imax\", \"imax\", \"immediately\", \"immediately\", \"inner\", \"inner\", \"interested\", \"interested\", \"interested\", \"invested\", \"invested\", \"ironic\", \"ironic\", \"ironic\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"irritating\", \"ita\", \"ita\", \"ita\", \"iteration\", \"iteration\", \"itgo\", \"itgo\", \"itthis\", \"itthis\", \"james\", \"james\", \"james\", \"james\", \"james\", \"james\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"jeffrey\", \"joe\", \"joe\", \"joe\", \"kane\", \"kane\", \"keeps\", \"keeps\", \"keeps\", \"keeps\", \"keeps\", \"knight\", \"knight\", \"knight\", \"knight\", \"knight\", \"knight\", \"knight\", \"knightthe\", \"knightthe\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kravitz\", \"kyle\", \"kyle\", \"kyle\", \"kyle\", \"kyle\", \"kyle\", \"kyle\", \"kyle\", \"kylecat\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"loud\", \"loud\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lowerim\", \"lowerim\", \"lowerim\", \"lowerim\", \"lt\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"madness\", \"madness\", \"majestic\", \"majestic\", \"majestic\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"making\", \"making\", \"making\", \"making\", \"mascarade\", \"mascarade\", \"matt\", \"matt\", \"matt\", \"matt\", \"matt\", \"matt\", \"matt\", \"matt\", \"matt\", \"mature\", \"mature\", \"means\", \"means\", \"means\", \"member\", \"member\", \"member\", \"men\", \"men\", \"men\", \"mess\", \"mess\", \"mess\", \"mess\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"misery\", \"misery\", \"misery\", \"missteps\", \"missteps\", \"missteps\", \"mistaken\", \"mistaken\", \"mistaken\", \"mode\", \"mode\", \"moisty\", \"moisty\", \"momentits\", \"momentits\", \"mood\", \"mood\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movieit\", \"movieit\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"movies\", \"moviethis\", \"moviethis\", \"moviethis\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"musicthe\", \"musicthe\", \"mysterythe\", \"mysterythe\", \"nearly\", \"nearly\", \"needsproduction\", \"negative\", \"negative\", \"niro\", \"niro\", \"noir\", \"noir\", \"noir\", \"noir\", \"noir\", \"noir\", \"noir\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nolan\", \"nowto\", \"number\", \"number\", \"number\", \"obvious\", \"obvious\", \"obvious\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"onto\", \"onto\", \"onto\", \"onto\", \"opening\", \"opening\", \"opening\", \"opening\", \"opening\", \"opening\", \"opening\", \"opening\", \"opening\", \"organic\", \"organic\", \"origin\", \"origin\", \"orphan\", \"orphan\", \"orphan\", \"oscar\", \"oscar\", \"oscar\", \"oscar\", \"overacting\", \"overacting\", \"overall\", \"overly\", \"overly\", \"pace\", \"pace\", \"pace\", \"parents\", \"parents\", \"parents\", \"parents\", \"parents\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattinson\", \"pattison\", \"pattison\", \"pattison\", \"pattison\", \"pattison\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"peak\", \"peak\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"penguin\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"performances\", \"performances\", \"performances\", \"performances\", \"pining\", \"pining\", \"pining\", \"pining\", \"pitiful\", \"pitiful\", \"pitiful\", \"please\", \"please\", \"please\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"plot\", \"populationpaul\", \"populationpaul\", \"populationpaul\", \"portion\", \"portion\", \"portion\", \"power\", \"precatwoman\", \"precatwoman\", \"presence\", \"presented\", \"presented\", \"privileged\", \"privileged\", \"privileged\", \"privileged\", \"privileged\", \"privileged\", \"pulls\", \"pulls\", \"quakes\", \"quakes\", \"quinn\", \"quinn\", \"quinn\", \"quite\", \"quite\", \"quite\", \"quite\", \"quite\", \"quite\", \"quite\", \"quite\", \"quite\", \"racked\", \"racked\", \"racked\", \"racked\", \"realise\", \"realise\", \"realise\", \"realise\", \"realizes\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recognise\", \"recognise\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reeves\", \"reevestotally\", \"reevestotally\", \"reigns\", \"reigns\", \"relationships\", \"relationships\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"reviews\", \"reviews\", \"reviews\", \"revs\", \"revs\", \"rewarding\", \"rewarding\", \"rewarding\", \"rhetoric\", \"rhetoric\", \"rhetoric\", \"rich\", \"rich\", \"rich\", \"ridding\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"riddler\", \"ripoff\", \"ripoff\", \"ripoff\", \"ripoff\", \"rob\", \"rob\", \"rob\", \"rob\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"robert\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"role\", \"saga\", \"saga\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scary\", \"scary\", \"scary\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"scenes\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"scowls\", \"screen\", \"screen\", \"script\", \"script\", \"script\", \"script\", \"script\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seemed\", \"seemed\", \"seemed\", \"seemed\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"selena\", \"selena\", \"selena\", \"selena\", \"selena\", \"sense\", \"sense\", \"sense\", \"sequel\", \"sequel\", \"sequel\", \"sequel\", \"sequel\", \"sequel\", \"shadow\", \"shadows\", \"shadows\", \"shadows\", \"shadows\", \"shadows\", \"shoehorned\", \"shoehorned\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shots\", \"shots\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"siege\", \"siege\", \"sleepy\", \"sleepy\", \"sleepy\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"somewhere\", \"sorely\", \"sorely\", \"sorely\", \"southamptonwith\", \"southamptonwith\", \"southamptonwith\", \"southamptonwith\", \"special\", \"special\", \"special\", \"specialbut\", \"specialbut\", \"specialbut\", \"specialbut\", \"spends\", \"spends\", \"sports\", \"sports\", \"standing\", \"standing\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"stops\", \"stops\", \"stories\", \"stories\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"story\", \"strains\", \"stuck\", \"stuck\", \"stuck\", \"stuck\", \"suddenly\", \"suddenly\", \"suddenly\", \"suddenly\", \"super\", \"super\", \"super\", \"super\", \"super\", \"super\", \"super\", \"surface\", \"surface\", \"surpassedrobert\", \"surpassedrobert\", \"surpassedrobert\", \"tall\", \"tall\", \"taxi\", \"telling\", \"terrible\", \"terrible\", \"terrible\", \"terrible\", \"terrible\", \"terrible\", \"terrorizing\", \"theatre\", \"theatre\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"theres\", \"theres\", \"theres\", \"theres\", \"theres\", \"theres\", \"theres\", \"theres\", \"theres\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"threat\", \"threat\", \"threat\", \"threat\", \"thrillingit\", \"thrillingit\", \"thrillingit\", \"throat\", \"throat\", \"throat\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tired\", \"tired\", \"together\", \"together\", \"together\", \"together\", \"together\", \"together\", \"together\", \"together\", \"ton\", \"ton\", \"toobeautifully\", \"toobeautifully\", \"toobeautifully\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"took\", \"topless\", \"topless\", \"topless\", \"topless\", \"totally\", \"totally\", \"tried\", \"tried\", \"tried\", \"trilogy\", \"trilogy\", \"trilogy\", \"trilogy\", \"trilogy\", \"true\", \"true\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"twilight\", \"twilight\", \"twilight\", \"twilight\", \"twilight\", \"twilight\", \"understand\", \"understand\", \"understand\", \"underwhelming\", \"underwhelming\", \"underwhelming\", \"underwhelming\", \"undeveloped\", \"undeveloped\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"unlikely\", \"unlikely\", \"vengeance\", \"versus\", \"versus\", \"view\", \"view\", \"viewing\", \"viewing\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"visceral\", \"visceral\", \"visceral\", \"visceral\", \"visceral\", \"visuals\", \"visuals\", \"waiting\", \"waiting\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"wayne\", \"ways\", \"ways\", \"wellmade\", \"wellmade\", \"weve\", \"weve\", \"weve\", \"weve\", \"weve\", \"weve\", \"weve\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"wings\", \"wings\", \"wings\", \"wings\", \"wise\", \"wise\", \"woke\", \"woke\", \"woke\", \"wondered\", \"wondered\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worse\", \"worse\", \"worse\", \"worse\", \"worse\", \"worse\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"worthy\", \"worthy\", \"worthy\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wraps\", \"wraps\", \"wraps\", \"wraps\", \"wright\", \"wright\", \"wright\", \"wright\", \"wright\", \"wright\", \"wright\", \"wright\", \"wright\", \"written\", \"wrong\", \"wrong\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\", \"youll\", \"youll\", \"youve\", \"youve\", \"youve\", \"zoe\", \"zoe\", \"zoe\", \"zoe\", \"zoe\", \"zoe\", \"zoe\", \"zoe\", \"zoe\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 6, 1, 7, 10, 3, 8, 5, 9]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1301616791366013602396759735\", ldavis_el1301616791366013602396759735_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1301616791366013602396759735\", ldavis_el1301616791366013602396759735_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1301616791366013602396759735\", ldavis_el1301616791366013602396759735_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "pyLDAvis.display(LDAvis_prepared)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster.\n",
        "\n",
        "For topic 1, the top 30 relevant terms are shown above. The most significant 5 terms are batman, movie, film, good, even. The word 'batman' appears 350 times, out of which 21% occurences are in the first cluster. Similarly, the no. of tokens and the frequency & proportion of tokens goes on decreasing from cluster 1 down to cluster 10. \n"
      ],
      "metadata": {
        "id": "Hg0UOlUQ7hX2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww1QRZSl1ODB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJvcQbxZ1ODB",
        "outputId": "95bf595d-4026-4ab0-e654-a4131ab792ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Collecting hdbscan>=0.8.29\n",
            "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentence-transformers>=0.4.1\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn>=0.5.0\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.22.4)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.13.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.34)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.1+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (67.7.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp310-cp310-linux_x86_64.whl size=3541540 sha256=ee49ca42d89520d0173e8ef7bc82c7db16210b6dae38c1217befc51daa89d976\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/52/e3/6c6b60b126b4d5c4370cb5ac071b82950f91649d62d72f7f56\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=a5745fc33473dc89f41a871dc1f1a76498b0638dbd947688aaeba63def372e46\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82830 sha256=9adf5a87c9d36b046bfd3f8984e8871e84263d3ba70710276beb54906554f7c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55640 sha256=583c8a8266a9b07f176d795f96da749deb66fd3fbbc548e2715bb5cf7ab3e2d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
            "Successfully installed bertopic-0.14.1 hdbscan-0.8.29 huggingface-hub-0.14.1 pynndescent-0.5.10 sentence-transformers-2.2.2 sentencepiece-0.1.98 tokenizers-0.13.3 transformers-4.28.1 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "# installed the bertopic library\n",
        "! pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9AZk4vI1ODC"
      },
      "outputs": [],
      "source": [
        "# imported the required libraries\n",
        "from bertopic import BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converted the data into list\n",
        "movies_data = df_movies.clean_text_processed.to_list()"
      ],
      "metadata": {
        "id": "wWBV0Ylk2BgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# created a topic model using English language words\n",
        "topic_model = BERTopic(language=\"english\")\n",
        "\n",
        "# come up with the topics count vs. their frequencies\n",
        "topics, probs = topic_model.fit_transform(movies_data)"
      ],
      "metadata": {
        "id": "D85TH-FR2FBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for given data with 100 rows, BERTModel comes up with 3 topics as shown below & their frequencies\n",
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GaOOtCNv2wxY",
        "outputId": "0233fa65-5280-45dd-a2f9-365d9d4e68ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Topic  Count              Name\n",
              "0      0     72   0_the_and_of_is\n",
              "1      1     16    1_the_of_in_to\n",
              "2      2     12  2_is_the_it_like"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7af003dc-5f08-44c6-a88d-44d18799db24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>0_the_and_of_is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1_the_of_in_to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2_is_the_it_like</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7af003dc-5f08-44c6-a88d-44d18799db24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7af003dc-5f08-44c6-a88d-44d18799db24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7af003dc-5f08-44c6-a88d-44d18799db24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the top 3 topics are shown below.\n",
        "topic_model.visualize_barchart(top_n_topics=10, n_words = 10, width = 350, height = 350)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5xIICYgl3PiV",
        "outputId": "c0e57ef2-cad7-469a-e2fb-8bfc53b61eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"fba2ba99-d017-4cc7-a69f-04f3189786cd\" class=\"plotly-graph-div\" style=\"height:455.0px; width:1400px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fba2ba99-d017-4cc7-a69f-04f3189786cd\")) {                    Plotly.newPlot(                        \"fba2ba99-d017-4cc7-a69f-04f3189786cd\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.03872549809263125,0.03896970117122214,0.04389242507962453,0.047465409771795114,0.04880623768430842,0.054094349719563145,0.05898701690449584,0.06234245827407223,0.08292998072300563,0.1112071512184741],\"y\":[\"that  \",\"it  \",\"batman  \",\"was  \",\"in  \",\"to  \",\"is  \",\"of  \",\"and  \",\"the  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.05001420711205119,0.05247234900436887,0.05721680480050603,0.05747048824200577,0.060018967487519656,0.06396360682969542,0.06644940033329862,0.07072854494222697,0.0810280215253644,0.12187580475000252],\"y\":[\"this  \",\"is  \",\"it  \",\"was  \",\"and  \",\"batman  \",\"to  \",\"in  \",\"of  \",\"the  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.0678512155752535,0.06905277290402044,0.07091545246173088,0.07091545246173088,0.07311959440519282,0.07492879657192891,0.07792657927071885,0.09774537486753114,0.10220948171079755,0.10326558284059792],\"y\":[\"movie  \",\"better  \",\"feels  \",\"score  \",\"universe  \",\"batman  \",\"like  \",\"it  \",\"the  \",\"is  \"],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 2\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1400,\"height\":455.0},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fba2ba99-d017-4cc7-a69f-04f3189786cd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(1) The features selected for building the classifier are as below:\n",
        "1. clean_text_processed column which contains the cleaned data containing the sentiments of the viewers. \n",
        "2. sentiment column which has the responses saved like - whether the text entered is positive, negative or neutral "
      ],
      "metadata": {
        "id": "q82tXmk0EKvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "\n",
        "# importing the required libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the regular expression library\n",
        "import re\n"
      ],
      "metadata": {
        "id": "PvdIwHAMKPc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.dev/ArtiPhadke/Arti_INFO5731_Spring2023/blob/main/movies_sentiment_data.csv\n",
        "df_movies=pd.read_csv('movies_sentiment_data.csv')\n",
        "print(df_movies.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prf6WC08BPN6",
        "outputId": "a391a26a-a2bd-4141-fcdb-ef6f930ac56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning & preprocessing steps\n",
        "\n",
        "# removing the special characters & punctuation marks\n",
        "df_movies['clean_text_processed'] = \\\n",
        "df_movies['clean_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "\n",
        "# converting to lowercase\n",
        "df_movies['clean_text_processed'] = \\\n",
        "df_movies['clean_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "# printing out the first few rows\n",
        "df_movies['clean_text_processed'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qidcOfbhBXNO",
        "outputId": "3805a43c-b39f-4e0e-b0d7-d39c34570f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    detective batman at its peak great storyline j...\n",
              "1    i just got out of the batmanthis movie really ...\n",
              "2    i have been absolutely fizzing to see the batm...\n",
              "3    the riddlerpaul dano spoton how did it take th...\n",
              "4    star rating  brilliant  very good  okay  poor ...\n",
              "Name: clean_text_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "outputs": [],
      "source": [
        "# TF-IDF processing with tri-grams selected for processing \n",
        "tf_idf= TfidfVectorizer(ngram_range=(1,3), max_features=1000)\n",
        "tf_idf.fit(df_movies['clean_text_processed'])\n",
        "\n",
        "# set the independent variable as the clean_text_processed\n",
        "x_values =  tf_idf.transform(df_movies['clean_text_processed'])\n",
        "\n",
        "# set the dependent variable as sentiment\n",
        "y_values = df_movies['sentiment']\n",
        "\n",
        "# splitting the training data to training and validating data with 20% division as validation data & 80% as training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_values, y_values, test_size = 0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(2) The supervised algorithms being used are: Naive Bayes & K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "m5kIdLMRNAMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries required for Naive Bayes supervised algorithm\n",
        "\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "jrSJ0g7UMFI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create, fit the model & predict the sentiment\n",
        "\n",
        "cl_NB  = naive_bayes.MultinomialNB()\n",
        "model_NB = cl_NB.fit(x_train,y_train)\n",
        "pr_NB  = cl_NB.predict(x_valid)"
      ],
      "metadata": {
        "id": "-Jh251yw_9ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy\n",
        "print (\"Accuracy = \", round(accuracy_score(y_valid, pr_NB)*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xJ0ODUZflqF",
        "outputId": "721f1843-cfe2-4d3f-a6ae-82f896f876b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy\n",
        "print (\"Precision = \", round(precision_score(y_valid, pr_NB, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jyqMLOEf7Pt",
        "outputId": "446d7e79-78fe-4408-e202-662deef979e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision =  85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Recall = \", round(recall_score(y_valid, pr_NB, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhgrabF4gDL_",
        "outputId": "74c589f5-556a-41f8-eae1-fb82111f991c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall =  85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"F1 Score = \", round(f1_score(y_valid, pr_NB, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1NjrU8KgHoI",
        "outputId": "422146ea-0738-4844-e497-2a64b7715c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score =  85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report - \")\n",
        "cr_NB = classification_report(y_valid, pr_NB)\n",
        "print(cr_NB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsM8bf6cgPW4",
        "outputId": "749a209f-06b8-4067-ed7b-775d43a35581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report - \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      1.00      0.87        10\n",
            "     neutral       1.00      0.40      0.57         5\n",
            "    positive       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.92      0.80      0.81        20\n",
            "weighted avg       0.88      0.85      0.83        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the evaluation matrices for training data & print the classification report\n",
        "pr_train_NB = cl_NB.predict(x_train)\n",
        "print(\"Classification Report - \")\n",
        "cr_train_KNN = classification_report(y_train, pr_train_NB)\n",
        "print(cr_train_KNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w-eClJiiicC",
        "outputId": "edfbe987-0af3-4c8b-9fc9-b1d64428e3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report - \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      1.00      0.94        38\n",
            "     neutral       1.00      0.67      0.80        15\n",
            "    positive       1.00      1.00      1.00        27\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.96      0.89      0.91        80\n",
            "weighted avg       0.94      0.94      0.93        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries required for Naive Bayes supervised algorithm\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "tOPOdm0aMtdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create, fit the model & predict the sentiment\n",
        "\n",
        "cl_KNN = KNeighborsClassifier(n_neighbors = 4)\n",
        "model_knn = cl_KNN.fit(x_train, y_train) \n",
        "pr_KNN = cl_KNN.predict(x_valid)"
      ],
      "metadata": {
        "id": "8GyX2K9qClQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Accuracy = \", round(accuracy_score(y_valid, pr_KNN)*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElaTfIXOgTPr",
        "outputId": "6363c15d-3a5e-481a-9a3a-26fbec2f8c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Percision = \", round(precision_score(y_valid, pr_KNN, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znG0vjvrgTWe",
        "outputId": "956cc71c-9e0a-4ab9-cbef-91d1bd2523e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percision =  75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Recall = \", round(recall_score(y_valid, pr_KNN, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6RGffuxgTcb",
        "outputId": "6cb8182d-b0b6-4260-b448-13c1b5506e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall =  75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"F1 Score = \", round(f1_score(y_valid, pr_KNN, labels='positive',average='micro')*100),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6QAAkAPgTiI",
        "outputId": "20a8000f-b99d-4ec2-e701-47bbf4beaaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score =  75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report - \")\n",
        "cr_KNN = classification_report(y_valid, pr_KNN)\n",
        "print(cr_KNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV3EYuLsgTpP",
        "outputId": "b6e23f50-5eea-431c-9320-bd4b26a4852e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report - \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      1.00      0.91        10\n",
            "     neutral       0.50      0.60      0.55         5\n",
            "    positive       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.75        20\n",
            "   macro avg       0.78      0.67      0.68        20\n",
            "weighted avg       0.79      0.75      0.73        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the evaluation matrices for training data & print the classification report\n",
        "pr_train_KNN = cl_KNN.predict(x_train)\n",
        "print(\"Classification Report - \")\n",
        "cr_train_KNN = classification_report(y_train, pr_train_KNN)\n",
        "print(cr_train_KNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wW-Xtq6gan9",
        "outputId": "9edc486c-eb05-421e-a340-4ba1ba248594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report - \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.95      1.00      0.97        38\n",
            "     neutral       0.93      0.87      0.90        15\n",
            "    positive       1.00      0.96      0.98        27\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.96      0.94      0.95        80\n",
            "weighted avg       0.96      0.96      0.96        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "\n",
        "(3) Comparison of NB & KNN:\n",
        "Accuracy, Recall, Precision & F-1 score: NB provides 85% and KNN provides 75%. Naive Bayes performs better in these criterias.\n",
        "Also looking at the classification report, Naive Bayes is a better choice."
      ],
      "metadata": {
        "id": "bLmY3g5hNjOD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "uwK8yszTlgzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "5BKJ8l4jlfd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "outputs": [],
      "source": [
        "# imported the data from training & test datasets\n",
        "df_house_train = pd.read_csv(\"train.csv\")\n",
        "df_house_test = pd.read_csv(\"test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view first few rows from training dataset\n",
        "df_house_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-2v7KSU8lLYi",
        "outputId": "f8a3ae63-6694-4888-a32a-a4777e7c2ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a12acc38-9199-4070-a8e3-bea21438095d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a12acc38-9199-4070-a8e3-bea21438095d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a12acc38-9199-4070-a8e3-bea21438095d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a12acc38-9199-4070-a8e3-bea21438095d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view first few rows from test dataset\n",
        "df_house_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "6EXq2YHhlNjQ",
        "outputId": "9cb24b72-77c0-4af1-fbbd-8e0a90dff6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
              "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
              "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      6    2010        WD         Normal  \n",
              "1   12500      6    2010        WD         Normal  \n",
              "2       0      3    2010        WD         Normal  \n",
              "3       0      6    2010        WD         Normal  \n",
              "4       0      1    2010        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02706b42-f155-4769-8dbe-654650b21f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02706b42-f155-4769-8dbe-654650b21f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02706b42-f155-4769-8dbe-654650b21f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02706b42-f155-4769-8dbe-654650b21f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the column 'Alley' as it contains maximum null values\n",
        "df_house_train = df_house_train.drop(['Alley'], axis=1)\n",
        "df_house_test = df_house_test.drop(['Alley'], axis=1)"
      ],
      "metadata": {
        "id": "EgB9gBbIlawe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removed null rows from the other columns\n",
        "df_house_train = df_house_train.select_dtypes(include=['number']).dropna()\n",
        "df_house_test = df_house_test.select_dtypes(include=['number']).dropna()"
      ],
      "metadata": {
        "id": "wPb0GvyGR76H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_house_train.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MvrHI8eUolM",
        "outputId": "61906f33-c759-4ba3-8cad-a5cc520769e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               1121\n",
              "MSSubClass       1121\n",
              "LotFrontage      1121\n",
              "LotArea          1121\n",
              "OverallQual      1121\n",
              "OverallCond      1121\n",
              "YearBuilt        1121\n",
              "YearRemodAdd     1121\n",
              "MasVnrArea       1121\n",
              "BsmtFinSF1       1121\n",
              "BsmtFinSF2       1121\n",
              "BsmtUnfSF        1121\n",
              "TotalBsmtSF      1121\n",
              "1stFlrSF         1121\n",
              "2ndFlrSF         1121\n",
              "LowQualFinSF     1121\n",
              "GrLivArea        1121\n",
              "BsmtFullBath     1121\n",
              "BsmtHalfBath     1121\n",
              "FullBath         1121\n",
              "HalfBath         1121\n",
              "BedroomAbvGr     1121\n",
              "KitchenAbvGr     1121\n",
              "TotRmsAbvGrd     1121\n",
              "Fireplaces       1121\n",
              "GarageYrBlt      1121\n",
              "GarageCars       1121\n",
              "GarageArea       1121\n",
              "WoodDeckSF       1121\n",
              "OpenPorchSF      1121\n",
              "EnclosedPorch    1121\n",
              "3SsnPorch        1121\n",
              "ScreenPorch      1121\n",
              "PoolArea         1121\n",
              "MiscVal          1121\n",
              "MoSold           1121\n",
              "YrSold           1121\n",
              "SalePrice        1121\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_house_test.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlNPz_0XUtEF",
        "outputId": "f5f9c851-e634-492e-d83b-f5867717bcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               1146\n",
              "MSSubClass       1146\n",
              "LotFrontage      1146\n",
              "LotArea          1146\n",
              "OverallQual      1146\n",
              "OverallCond      1146\n",
              "YearBuilt        1146\n",
              "YearRemodAdd     1146\n",
              "MasVnrArea       1146\n",
              "BsmtFinSF1       1146\n",
              "BsmtFinSF2       1146\n",
              "BsmtUnfSF        1146\n",
              "TotalBsmtSF      1146\n",
              "1stFlrSF         1146\n",
              "2ndFlrSF         1146\n",
              "LowQualFinSF     1146\n",
              "GrLivArea        1146\n",
              "BsmtFullBath     1146\n",
              "BsmtHalfBath     1146\n",
              "FullBath         1146\n",
              "HalfBath         1146\n",
              "BedroomAbvGr     1146\n",
              "KitchenAbvGr     1146\n",
              "TotRmsAbvGrd     1146\n",
              "Fireplaces       1146\n",
              "GarageYrBlt      1146\n",
              "GarageCars       1146\n",
              "GarageArea       1146\n",
              "WoodDeckSF       1146\n",
              "OpenPorchSF      1146\n",
              "EnclosedPorch    1146\n",
              "3SsnPorch        1146\n",
              "ScreenPorch      1146\n",
              "PoolArea         1146\n",
              "MiscVal          1146\n",
              "MoSold           1146\n",
              "YrSold           1146\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the SalePrice column as it is dependent variable, and dropping id as it is not required\n",
        "x_train_data = df_house_train.drop(['SalePrice','Id'], axis=1)\n",
        "\n",
        "# create dependent data column using SalePrice price\n",
        "y_train_data = np.log(df_house_train.SalePrice)"
      ],
      "metadata": {
        "id": "NghUN2B7lbPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the data into train (80%) & test (20%) dataset, with 20% split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train_data,y_train_data,random_state = 202, test_size=0.2)"
      ],
      "metadata": {
        "id": "G7MDWgYWmdXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create logistic regression model\n",
        "model_Log = LinearRegression()\n",
        "model_Log.fit(x_train,y_train)\n",
        "\n",
        "# predict the SalePrice using the model\n",
        "y_pred = model_Log.predict(x_test)"
      ],
      "metadata": {
        "id": "lLLSGUTKlbRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the R-square value, which is 88% so the regression model is working well on the predicting the sentiment using the data\n",
        "print('R-square value for logistic regression is:\": %.4f' % model_Log.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Y6kAMKmwRb",
        "outputId": "e87ea75f-cbc6-404a-8485-1ca264b4a6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-square value for logistic regression is:\": 0.8876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the RMSE value, lower value is preferred\n",
        "MSE = mean_squared_error(np.exp(y_pred), y_test)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW6Ls_JPnCr2",
        "outputId": "78f72ae6-09be-4809-d65d-225b7c7c4197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198633.34989597762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the actual and predicted prices\n",
        "pred_vs_act = {\"Predicted Prices\":np.exp(y_pred),\"Actual Prices\":np.exp(y_test)}\n",
        "df_pred_vs_act = pd.DataFrame(pred_vs_act)\n",
        "\n",
        "print(df_pred_vs_act)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0NgnKLsnKEf",
        "outputId": "a04b117d-b266-43ce-cc00-0dda08f73a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Predicted Prices  Actual Prices\n",
            "344       89808.790434        85000.0\n",
            "1425     143859.897514       142000.0\n",
            "779      137577.206721       135000.0\n",
            "477      360850.081194       380000.0\n",
            "1329     206611.349810       176500.0\n",
            "...                ...            ...\n",
            "481      320852.962588       374000.0\n",
            "1344     204194.956073       155835.0\n",
            "715      160319.291309       165000.0\n",
            "1069     125185.445997       135000.0\n",
            "923      180019.730940       193000.0\n",
            "\n",
            "[225 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the % difference, showing the accuracy\n",
        "df_pred_vs_act[\"Percentage Difference\"] = round(abs((df_pred_vs_act[\"Predicted Prices\"] - df_pred_vs_act[\"Actual Prices\"]) / df_pred_vs_act[\"Actual Prices\"]) * 100,2)\n",
        "df_pred_vs_act"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3A9bxrpKnPlJ",
        "outputId": "46ad21b1-5dd6-4b06-a10e-8f3e4327b64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Predicted Prices  Actual Prices  Percentage Difference\n",
              "344       89808.790434        85000.0                   5.66\n",
              "1425     143859.897514       142000.0                   1.31\n",
              "779      137577.206721       135000.0                   1.91\n",
              "477      360850.081194       380000.0                   5.04\n",
              "1329     206611.349810       176500.0                  17.06\n",
              "...                ...            ...                    ...\n",
              "481      320852.962588       374000.0                  14.21\n",
              "1344     204194.956073       155835.0                  31.03\n",
              "715      160319.291309       165000.0                   2.84\n",
              "1069     125185.445997       135000.0                   7.27\n",
              "923      180019.730940       193000.0                   6.73\n",
              "\n",
              "[225 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d767e803-c7d6-4185-8be1-4fb15b16f64e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Prices</th>\n",
              "      <th>Actual Prices</th>\n",
              "      <th>Percentage Difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>89808.790434</td>\n",
              "      <td>85000.0</td>\n",
              "      <td>5.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>143859.897514</td>\n",
              "      <td>142000.0</td>\n",
              "      <td>1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>137577.206721</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>1.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>360850.081194</td>\n",
              "      <td>380000.0</td>\n",
              "      <td>5.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>206611.349810</td>\n",
              "      <td>176500.0</td>\n",
              "      <td>17.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>320852.962588</td>\n",
              "      <td>374000.0</td>\n",
              "      <td>14.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1344</th>\n",
              "      <td>204194.956073</td>\n",
              "      <td>155835.0</td>\n",
              "      <td>31.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>160319.291309</td>\n",
              "      <td>165000.0</td>\n",
              "      <td>2.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>125185.445997</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>7.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>180019.730940</td>\n",
              "      <td>193000.0</td>\n",
              "      <td>6.73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>225 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d767e803-c7d6-4185-8be1-4fb15b16f64e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d767e803-c7d6-4185-8be1-4fb15b16f64e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d767e803-c7d6-4185-8be1-4fb15b16f64e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}